"""
RCC (Regional Coordinating Committee) PDFæ•°æ®æå–æ¨¡å—

æœ¬æ¨¡å—è´Ÿè´£ä»RCCçš„PDFæ–‡ä»¶ä¸­æå–SRRæ¡ˆä»¶æ•°æ®ï¼Œä¸»è¦å¤„ç†RCCå¼€å¤´çš„PDFæ–‡ä»¶ã€‚
ç”±äºRCCæ–‡ä»¶å¯èƒ½æ˜¯æ‰«æä»¶æˆ–åŠ å¯†æ–‡ä»¶ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ã€‚

RCC PDFæ–‡ä»¶ç»“æ„ç‰¹ç‚¹ï¼š
- æ–œå¡ç·¨è™Ÿ å¯¹åº” G_slope_no
- æ¡ˆä»¶ç¼–å· å¯¹åº” C_1823_case_no
- æ—¥æœŸä¿¡æ¯ å¯¹åº” A_date_received
- æ¥æºä¿¡æ¯ å¯¹åº” B_source
- è”ç³»ä¿¡æ¯ å¯¹åº” E_caller_name, F_contact_no

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0
"""
import re
import os
import pdfplumber
import PyPDF2
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, Tuple, Dict, Any
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai.ai_case_type_classifier import classify_case_type_ai
from ai.ai_subject_matter_classifier import classify_subject_matter_ai
from ai.ai_request_summarizer import generate_ai_request_summary
from utils.slope_location_mapper import get_location_from_slope_no
from utils.source_classifier import classify_source_smart


def parse_date(date_str: str) -> Optional[datetime]:
    """
    è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡ï¼ˆç”¨äºè®¡ç®—ï¼‰ï¼Œå¤±è´¥è¿”å›None
    
    Args:
        date_str (str): æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        
    Returns:
        Optional[datetime]: è§£ææˆåŠŸè¿”å›datetimeå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
    """
    if not date_str:
        return None
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    date_formats = [
        "%Y-%m-%d",      # "2025-01-21"
        "%Y/%m/%d",      # "2025/03/18"
        "%d/%m/%Y",      # "21/01/2025"
        "%d-%m-%Y",      # "21-01-2025"
        "%d %B %Y",      # "21 January 2025"
        "%Yå¹´%mæœˆ%dæ—¥",   # "2025å¹´01æœˆ21æ—¥"
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except ValueError:
            continue
    
    return None


def format_date(dt: Optional[datetime]) -> str:
    """
    å°†datetimeå¯¹è±¡æ ¼å¼åŒ–ä¸ºdd-MMM-yyyyæ ¼å¼ï¼ŒNoneè¿”å›ç©º
    
    Args:
        dt (Optional[datetime]): è¦æ ¼å¼åŒ–çš„datetimeå¯¹è±¡
        
    Returns:
        str: dd-MMM-yyyyæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚ "15-Jan-2024"
    """
    return dt.strftime("%d-%b-%Y") if dt else ""


def calculate_due_date(base_date: Optional[datetime], days: int) -> str:
    """
    è®¡ç®—åŸºå‡†æ—¥æœŸåŠ dayså¤©åçš„æ—¥æœŸï¼Œè¿”å›ISOå­—ç¬¦ä¸²
    
    Args:
        base_date (Optional[datetime]): åŸºå‡†æ—¥æœŸ
        days (int): è¦æ·»åŠ çš„å¤©æ•°
        
    Returns:
        str: è®¡ç®—åçš„æ—¥æœŸISOå­—ç¬¦ä¸²
    """
    if not base_date:
        return ""
    return format_date(base_date + timedelta(days=days))


def extract_content_with_multiple_methods(pdf_path: str) -> str:
    """
    ä½¿ç”¨å¤šç§æ–¹æ³•æå–PDFå†…å®¹ï¼ŒåŒ…æ‹¬å¤„ç†æ—‹è½¬é¡µé¢
    
    Args:
        pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: æå–çš„æ–‡æœ¬å†…å®¹
    """
    content = ""
    
    # æ–¹æ³•1: ä½¿ç”¨pdfplumberï¼Œå¤„ç†æ—‹è½¬é¡µé¢
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for i, page in enumerate(pdf.pages):
                # æ£€æŸ¥é¡µé¢æ—‹è½¬
                rotation = getattr(page, 'rotation', 0)
                if rotation:
                    print(f"æ£€æµ‹åˆ°é¡µé¢{i+1}æ—‹è½¬: {rotation}åº¦")
                
                # å°è¯•åŸå§‹æå–
                text = page.extract_text()
                if text:
                    content += text + "\n"
                else:
                    # å¦‚æœåŸå§‹æå–å¤±è´¥ï¼Œå°è¯•ä¸åŒçš„å‚æ•°
                    try:
                        # å°è¯•ä¸åŒçš„æ–‡æœ¬æå–å‚æ•°
                        text = page.extract_text(
                            x_tolerance=3,
                            y_tolerance=3,
                            layout=True,
                            x_density=7.25,
                            y_density=13
                        )
                        if text:
                            content += text + "\n"
                            print(f"ä½¿ç”¨ç‰¹æ®Šå‚æ•°æˆåŠŸæå–é¡µé¢{i+1}æ–‡æœ¬")
                    except Exception as e:
                        print(f"ç‰¹æ®Šå‚æ•°æå–å¤±è´¥: {e}")
                        
    except Exception as e:
        print(f"pdfplumberæå–å¤±è´¥: {e}")
    
    # æ–¹æ³•2: ä½¿ç”¨PyPDF2
    if not content:
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                for i, page in enumerate(reader.pages):
                    text = page.extract_text()
                    if text:
                        content += text + "\n"
                    else:
                        # å°è¯•ä¸åŒçš„æå–æ–¹æ³•
                        try:
                            # å°è¯•æå–æ–‡æœ¬æµ
                            if hasattr(page, 'get_contents'):
                                contents = page.get_contents()
                                if contents:
                                    print(f"é¡µé¢{i+1}åŒ…å«å†…å®¹æµï¼Œä½†æ— æ³•ç›´æ¥æå–æ–‡æœ¬")
                        except Exception as e:
                            print(f"é¡µé¢{i+1}å†…å®¹æµæå–å¤±è´¥: {e}")
        except Exception as e:
            print(f"PyPDF2æå–å¤±è´¥: {e}")
    
    # æ–¹æ³•3: å°è¯•å¿«é€ŸOCR (å¦‚æœå®‰è£…äº†ç›¸å…³åº“)
    if not content:
        try:
            content = extract_text_with_ocr_fast(pdf_path)
        except Exception as e:
            print(f"å¿«é€ŸOCRæå–å¤±è´¥: {e}")
    
    return content


def extract_text_with_ocr_fast(pdf_path: str) -> str:
    """
    å¿«é€ŸOCRå¤„ç†ï¼Œä¼˜å…ˆé€Ÿåº¦ï¼Œé™åˆ¶å¤„ç†æ—¶é—´
    """
    import time
    start_time = time.time()
    max_processing_time = 60  # æœ€å¤§å¤„ç†æ—¶é—´60ç§’
    content = ""
    
    # åªä½¿ç”¨æœ€å¿«çš„EasyOCRæ–¹æ³•
    try:
        import easyocr
        import fitz  # PyMuPDF
        from PIL import Image
        import io
        
        print("ä½¿ç”¨å¿«é€ŸEasyOCRæå–æ–‡æœ¬...")
        
        # åˆå§‹åŒ–EasyOCR (åªä½¿ç”¨è‹±æ–‡ï¼Œæœ€å¿«è®¾ç½®)
        reader = easyocr.Reader(['en'], gpu=False, verbose=False, download_enabled=False)
        
        doc = fitz.open(pdf_path)
        
        # åªå¤„ç†å‰2é¡µï¼Œé¿å…å¤„ç†æ—¶é—´è¿‡é•¿
        max_pages = min(2, len(doc))
        
        for page_num in range(max_pages):
            # æ£€æŸ¥å¤„ç†æ—¶é—´é™åˆ¶
            if time.time() - start_time > max_processing_time:
                print(f"â° å¿«é€ŸOCRå¤„ç†è¶…æ—¶({max_processing_time}ç§’)ï¼Œåœæ­¢å¤„ç†")
                break
                
            page = doc.load_page(page_num)
            
            # ä½¿ç”¨æ›´ä½çš„åˆ†è¾¨ç‡ï¼Œä¼˜å…ˆé€Ÿåº¦
            mat = fitz.Matrix(1.5, 1.5)  # è¿›ä¸€æ­¥é™ä½åˆ°1.5å€åˆ†è¾¨ç‡
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            
            # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ
            image = Image.open(io.BytesIO(img_data))
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ (EasyOCRéœ€è¦numpyæ•°ç»„)
            import numpy as np
            image_array = np.array(image)
            
            # ä½¿ç”¨EasyOCRè¿›è¡ŒOCRï¼Œé™ä½ç½®ä¿¡åº¦é˜ˆå€¼
            results = reader.readtext(image_array)
            
            # æå–æ–‡æœ¬
            page_text = ""
            for (bbox, text, confidence) in results:
                if confidence > 0.2:  # è¿›ä¸€æ­¥é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
                    page_text += text + " "
            
            if page_text.strip():
                content += page_text.strip() + "\n"
                print(f"å¿«é€ŸOCRæˆåŠŸæå–é¡µé¢{page_num+1}æ–‡æœ¬: {len(page_text)}å­—ç¬¦")
        
        doc.close()
        
        if content.strip():
            processing_time = time.time() - start_time
            print(f"âœ… å¿«é€ŸOCRå®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return content
        
    except ImportError:
        print("EasyOCRæœªå®‰è£…ï¼Œè·³è¿‡å¿«é€ŸOCR")
    except Exception as e:
        print(f"å¿«é€ŸOCRæå–å¼‚å¸¸: {e}")
    
    # å¦‚æœå¿«é€ŸOCRå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
    print("å¿«é€ŸOCRå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸOCRæ–¹æ³•...")
    return extract_text_with_ocr_traditional(pdf_path)


def extract_text_with_ocr(pdf_path: str) -> str:
    """
    ä½¿ç”¨OCRæŠ€æœ¯ä»PDFä¸­æå–æ–‡æœ¬ï¼Œä¼˜å…ˆé€Ÿåº¦
    
    Args:
        pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: OCRæå–çš„æ–‡æœ¬å†…å®¹
    """
    # ç›´æ¥ä½¿ç”¨å¿«é€ŸOCRï¼Œè·³è¿‡AIå¢å¼ºå¤„ç†
    print("ä½¿ç”¨å¿«é€ŸOCRæå–æ–‡æœ¬...")
    return extract_text_with_ocr_fast(pdf_path)


def extract_text_with_ocr_traditional(pdf_path: str) -> str:
    """
    ä¼ ç»ŸOCRæ–¹æ³•ä½œä¸ºå¤‡é€‰ï¼Œé™åˆ¶å¤„ç†æ—¶é—´
    """
    import time
    start_time = time.time()
    max_processing_time = 90  # æœ€å¤§å¤„ç†æ—¶é—´90ç§’
    content = ""
    
    # æ–¹æ³•1: å°è¯•EasyOCR 
    try:
        import easyocr
        import fitz  # PyMuPDF
        from PIL import Image
        import io
        
        print("ä½¿ç”¨ä¼ ç»ŸEasyOCRæå–æ–‡æœ¬...")
        
        # åˆå§‹åŒ–EasyOCR (åªä½¿ç”¨è‹±æ–‡ï¼Œé¿å…è¯­è¨€å†²çªï¼Œæé«˜é€Ÿåº¦)
        reader = easyocr.Reader(['en'], gpu=False, verbose=False, download_enabled=False)
        
        doc = fitz.open(pdf_path)
        
        for page_num in range(len(doc)):
            # æ£€æŸ¥å¤„ç†æ—¶é—´é™åˆ¶
            if time.time() - start_time > max_processing_time:
                print(f"â° OCRå¤„ç†è¶…æ—¶({max_processing_time}ç§’)ï¼Œåœæ­¢å¤„ç†")
                break
                
            page = doc.load_page(page_num)
            
            # è·å–é¡µé¢å›¾åƒï¼Œå¤„ç†æ—‹è½¬ (è¿›ä¸€æ­¥é™ä½åˆ†è¾¨ç‡ä»¥æé«˜é€Ÿåº¦)
            mat = fitz.Matrix(1.8, 1.8)  # é™ä½åˆ°1.8å€åˆ†è¾¨ç‡ï¼Œä¼˜å…ˆé€Ÿåº¦
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            
            # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ
            image = Image.open(io.BytesIO(img_data))
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ (EasyOCRéœ€è¦numpyæ•°ç»„)
            import numpy as np
            image_array = np.array(image)
            
            # ä½¿ç”¨EasyOCRè¿›è¡ŒOCR
            results = reader.readtext(image_array)
            
            # æå–æ–‡æœ¬
            page_text = ""
            for (bbox, text, confidence) in results:
                if confidence > 0.3:  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥è·å–æ›´å¤šæ–‡æœ¬
                    page_text += text + " "
            
            if page_text.strip():
                content += page_text.strip() + "\n"
                print(f"EasyOCRæˆåŠŸæå–é¡µé¢{page_num+1}æ–‡æœ¬: {len(page_text)}å­—ç¬¦")
        
        doc.close()
        return content
        
    except ImportError:
        print("EasyOCRæœªå®‰è£…ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
    except Exception as e:
        print(f"EasyOCRæå–å¼‚å¸¸: {e}")
    
    # æ–¹æ³•2: å°è¯•Tesseract OCR (å¤‡é€‰)
    try:
        import fitz  # PyMuPDF
        import pytesseract
        from PIL import Image
        import io
        
        print("ä½¿ç”¨Tesseract OCRæå–æ–‡æœ¬...")
        
        doc = fitz.open(pdf_path)
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            
            # è·å–é¡µé¢å›¾åƒ (è¿›ä¸€æ­¥é™ä½åˆ†è¾¨ç‡ä»¥æé«˜é€Ÿåº¦)
            mat = fitz.Matrix(1.8, 1.8)  # é™ä½åˆ°1.8å€åˆ†è¾¨ç‡ï¼Œä¼˜å…ˆé€Ÿåº¦
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            
            # ä½¿ç”¨PILæ‰“å¼€å›¾åƒ
            image = Image.open(io.BytesIO(img_data))
            
            # ä½¿ç”¨Tesseractè¿›è¡ŒOCR
            text = pytesseract.image_to_string(image, lang='chi_sim+eng')
            if text.strip():
                content += text + "\n"
                print(f"TesseractæˆåŠŸæå–é¡µé¢{page_num+1}æ–‡æœ¬")
        
        doc.close()
        return content
        
    except ImportError:
        print("Tesseract OCRæœªå®‰è£…ï¼Œè·³è¿‡OCRæå–")
        return ""
    except Exception as e:
        print(f"Tesseract OCRæå–å¼‚å¸¸: {e}")
        return ""
    
    # æ–¹æ³•3: å°è¯•pdf2image + OCR
    try:
        from pdf2image import convert_from_path
        import easyocr
        
        print("ä½¿ç”¨pdf2image + EasyOCRæå–æ–‡æœ¬...")
        
        # å°†PDFè½¬æ¢ä¸ºå›¾åƒ (è¿›ä¸€æ­¥é™ä½DPIä»¥æé«˜é€Ÿåº¦)
        images = convert_from_path(pdf_path, dpi=150)
        
        # åˆå§‹åŒ–EasyOCR (ä¼˜åŒ–é€Ÿåº¦)
        reader = easyocr.Reader(['en'], gpu=False, verbose=False, download_enabled=False)
        
        for i, image in enumerate(images):
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ (EasyOCRéœ€è¦numpyæ•°ç»„)
            import numpy as np
            image_array = np.array(image)
            
            # ä½¿ç”¨EasyOCRè¿›è¡ŒOCR
            results = reader.readtext(image_array)
            
            # æå–æ–‡æœ¬
            page_text = ""
            for (bbox, text, confidence) in results:
                if confidence > 0.3:  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥è·å–æ›´å¤šæ–‡æœ¬
                    page_text += text + " "
            
            if page_text.strip():
                content += page_text.strip() + "\n"
                print(f"pdf2image+EasyOCRæˆåŠŸæå–é¡µé¢{i+1}æ–‡æœ¬: {len(page_text)}å­—ç¬¦")
        
        return content
        
    except ImportError:
        print("pdf2imageæœªå®‰è£…ï¼Œè·³è¿‡æ­¤æ–¹æ³•")
        return ""
    except Exception as e:
        print(f"pdf2image+OCRæå–å¼‚å¸¸: {e}")
        return ""
    
    print("æ‰€æœ‰OCRæ–¹æ³•éƒ½ä¸å¯ç”¨ï¼Œè¯·å®‰è£…ç›¸å…³åº“")
    return ""


def extract_rcc_case_number(content: str, pdf_path: str = None) -> str:
    """
    æå–RCCæ¡ˆä»¶ç¼–å·
    
    ä¼˜å…ˆä»æ–‡ä»¶åæå–RCC#åé¢çš„æ•°å­—ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»PDFå†…å®¹ä¸­æå–
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: RCCæ¡ˆä»¶ç¼–å·
    """
    # ä¼˜å…ˆä»æ–‡ä»¶åæå–RCC#åé¢çš„æ•°å­—
    if pdf_path:
        filename = os.path.basename(pdf_path)
        filename_match = re.search(r'RCC[#\s]*(\d+)', filename, re.IGNORECASE)
        if filename_match:
            case_number = filename_match.group(1)
            print(f"âœ… ä»æ–‡ä»¶åæå–RCCæ¡ˆä»¶ç¼–å·: {case_number}")
            return case_number
    
    # å¦‚æœæ–‡ä»¶åä¸­æ²¡æœ‰ï¼Œåˆ™ä»PDFå†…å®¹ä¸­æå–
    patterns = [
        r'Call\s+Reference\s+No[:\s]+(\d+)',  # Call Reference No: 84878800
        r'RCC[#\s]*(\d+)',                    # RCC#84878800
        r'æ¡ˆä»¶ç·¨è™Ÿ[ï¼š:]\s*([A-Z0-9\-]+)',      # æ¡ˆä»¶ç·¨è™Ÿ: XXX
        r'Case\s+No\.?\s*([A-Z0-9\-]+)',      # Case No. XXX
        r'ç·¨è™Ÿ[ï¼š:]\s*([A-Z0-9\-]+)',         # ç·¨è™Ÿ: XXX
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            case_number = match.group(1).strip()
            print(f"âœ… ä»PDFå†…å®¹æå–RCCæ¡ˆä»¶ç¼–å·: {case_number}")
            return case_number
    
    print("âš ï¸ æœªæ‰¾åˆ°RCCæ¡ˆä»¶ç¼–å·")
    return ""


def extract_slope_number(content: str) -> str:
    """
    æå–æ–œå¡ç¼–å·
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: æ–œå¡ç¼–å·
    """
    # åŒ¹é…å„ç§å¯èƒ½çš„æ–œå¡ç¼–å·æ ¼å¼
    patterns = [
        r'æ–œå¡ç·¨è™Ÿ[ï¼š:ç‚ºä¸º]?\s*([A-Z0-9\-/]+)',  # æ–œå¡ç·¨è™Ÿ: XXX
        r'Slope\s+No\.?\s*([A-Z0-9\-/]+)',      # Slope No. XXX
        r'æ–œå¡ç‰Œè™Ÿ[ï¼š:ç‚ºä¸º]?\s*([A-Z0-9\-/]+)',  # æ–œå¡ç‰Œè™Ÿ: XXX
        r'ç·¨è™Ÿ[ï¼š:]\s*([A-Z0-9\-/]+)',         # ç·¨è™Ÿ: XXX
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            return match.group(1).strip().upper()
    
    return ""


def extract_date_from_content(content: str) -> str:
    """
    ä»RCCå†…å®¹ä¸­æå–æ—¥æœŸä¿¡æ¯
    
    Args:
        content (str): RCCæ–‡æœ¬å†…å®¹
        
    Returns:
        str: æ—¥æœŸå­—ç¬¦ä¸²
    """
    # ä¼˜å…ˆåŒ¹é…Handle Date (OCRå¯èƒ½è¯†åˆ«ä¸ºIIandle)
    date_patterns = [
        r'[Hh]andle\s+[Dd]ate[:\s]+(\d{4}[/-]\d{1,2}[/-]\d{1,2})',
        r'IIandle\s+[Dd]ate[:\s]+(\d{4}[/-]\d{1,2}[/-]\d{1,2})',  # OCRå¯èƒ½å°†Hè¯†åˆ«ä¸ºII
        r'Call-in\s+Date[:\s]+(\d{4}[/-]\d{1,2}[/-]\d{1,2})',
        r'Date[:\s]+(\d{4}[/-]\d{1,2}[/-]\d{1,2})',
        r'(\d{4}[/-]\d{1,2}[/-]\d{1,2})',  # YYYY/MM/DD æˆ– YYYY-MM-DD
        r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',  # DD/MM/YYYY æˆ– DD-MM-YYYY
        r'(\d{1,2}\s+\w+\s+\d{4})',  # DD Month YYYY
        r'(\w+\s+\d{1,2},?\s+\d{4})'  # Month DD, YYYY
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            date_str = match.group(1).strip()
            # æ¸…ç†æ—¥æœŸå­—ç¬¦ä¸²ï¼Œç§»é™¤æ—¶é—´éƒ¨åˆ†
            date_str = re.sub(r'\s+\d{1,2}:\d{2}:\d{2}', '', date_str)
            return date_str
    
    return ""


def extract_source_info(content: str) -> str:
    """
    æå–æ¥æºä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: æ¥æºä¿¡æ¯
    """
    # åŒ¹é…æ¥æºä¿¡æ¯
    patterns = [
        r'ä¾†æº[ï¼š:]\s*([^\n]+)',      # ä¾†æº: XXX
        r'Source[ï¼š:]\s*([^\n]+)',    # Source: XXX
        r'From[ï¼š:]\s*([^\n]+)',      # From: XXX
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            source = match.group(1).strip()
            if "RCC" in source.upper():
                return "RCC"
            return source
    
    return "RCC"  # é»˜è®¤è¿”å›RCC


def extract_contact_info(content: str) -> Tuple[str, str]:
    """
    æå–è”ç³»äººä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        Tuple[str, str]: (è”ç³»äººå§“å, è”ç³»ç”µè¯)
    """
    # åŒ¹é…è”ç³»äººä¿¡æ¯ - ä¼˜åŒ–OCRè¯†åˆ«
    name_patterns = [
        r'Name\s*:\s*of\s*Client[:\s]+([A-Za-z\s]+?)(?=\s+Contact\s+Tel\s+No)',  # Name: of Client: Sung Man Contact Tel No
        r'Name\s+of\s+Client[:\s]+([A-Za-z\s]+?)(?=\s+Contact\s+Tel\s+No)',  # Name of Client: Sung Man Contact Tel No
        r'Nale\s+of\s+Client[:\s]+([A-Za-z\s]+?)(?=\s+Contact\s+Tel\s+No)',  # Nale of Client: (OCRå¯èƒ½å°†Nameè¯†åˆ«ä¸ºNale)
        r'Name\s+of\s+client[:\s]+([A-Za-z\s]+?)(?=\s+Contact\s+Tel\s+No)',  # Name of client: Sung Man Contact Tel No
        r'Contact\s+person\s+\'s\s+Name\s+\(on\s+Site\)[:\s]+([^\n]+?)(?=\s+Title)',  # Contact person's Name (on Site): XXX
        r'è¯çµ¡äºº[ï¼š:]\s*([^\n]+)',      # è¯çµ¡äºº: XXX
        r'Contact[ï¼š:]\s*([^\n]+)',      # Contact: XXX
        r'å§“å[ï¼š:]\s*([^\n]+)',        # å§“å: XXX
        r'Name[ï¼š:]\s*([^\n]+)',        # Name: XXX
    ]
    
    phone_patterns = [
        r'Contact\s+Tel\s+No[:\s]+(\d+)',  # Contact Tel No: 25300155
        r'é›»è©±[ï¼š:]\s*([^\n]+)',       # é›»è©±: XXX
        r'Phone[ï¼š:]\s*([^\n]+)',       # Phone: XXX
        r'è¯çµ¡é›»è©±[ï¼š:]\s*([^\n]+)',    # è¯çµ¡é›»è©±: XXX
        r'Tel[ï¼š:]\s*([^\n]+)',        # Tel: XXX
    ]
    
    name = ""
    phone = ""
    
    for pattern in name_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            name = match.group(1).strip()
            # æ¸…ç†OCRé”™è¯¯ï¼Œå¦‚"of Client: Sung Man" -> "Sung Man"
            if "of Client:" in name:
                name = name.replace("of Client:", "").strip()
            break
    
    for pattern in phone_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            phone = match.group(1).strip()
            break
    
    return name, phone


def extract_slope_number(content: str) -> str:
    """
    æå–æ–œå¡ç¼–å·ï¼Œæ”¯æŒå¤šç§æ¨¡å¼å¹¶å»é™¤å¹²æ‰°ä¿¡æ¯
    
    æ”¯æŒçš„æå–æ¨¡å¼ï¼š
    1. slope.no åé¢çš„å†…å®¹
    2. Form 2 ref. no åé¢çš„å†…å®¹ä¸­æå–
    3. æ–œå¡ç¼–å· åé¢çš„å†…å®¹
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: æ¸…ç†åçš„æ–œå¡ç¼–å·
    """
    print("ğŸ” RCCå¼€å§‹æå–æ–œå¡ç¼–å·...")
    
    # æ¨¡å¼1: slope.no åé¢çš„å†…å®¹
    slope_no_patterns = [
        r'slope\.?\s*no\.?\s*[:\s]+([A-Z0-9\-/#\s]+)',  # slope.no: 11SW-D/CR995
        r'slope\s+no\.?\s*[:\s]+([A-Z0-9\-/#\s]+)',     # slope no: 11SW-D/CR995
        r'slope\s*[:\s]+([A-Z0-9\-/#\s]+)',             # slope: 11SW-D/CR995
    ]
    
    for pattern in slope_no_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_rcc(match.group(1))
            if slope_no:
                print(f"âœ… ä»slope.noæå–æ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    # æ¨¡å¼2: Form 2 ref. no åé¢çš„å†…å®¹ä¸­æå–
    form_ref_patterns = [
        r'Form\s+2\s+ref\.?\s+no\.?\s*[:\s]+form2-([A-Z0-9/#\s]+?)(?:-\d{8}-\d{3}|$)',  # Form 2 ref. no: form2-11SWB/F199-20241028-002
        r'form2-([A-Z0-9/#\s]+?)(?:-\d{8}-\d{3}|$)',  # form2-11SWB/F199-20241028-002ï¼Œåªæå–æ–œå¡ç¼–å·éƒ¨åˆ†
    ]
    
    for pattern in form_ref_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            extracted = match.group(1)
            # æ ¼å¼åŒ–æ–œå¡ç¼–å·
            slope_no = format_slope_number_rcc(extracted)
            
            if slope_no:
                print(f"âœ… ä»Form 2 ref. noæå–æ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    # æ¨¡å¼3: æ–œå¡ç¼–å· åé¢çš„å†…å®¹
    chinese_patterns = [
        r'æ–œå¡[ï¼ˆ(]ç·¨è™Ÿ[ï¼‰)][:\s]+([A-Z0-9\-/#\s]+)',  # æ–œå¡ï¼ˆç·¨è™Ÿï¼‰: 11SW-D/CR995
        r'æ–œå¡ç·¨è™Ÿ[:\s]+([A-Z0-9\-/#\s]+)',           # æ–œå¡ç·¨è™Ÿ: 11SW-D/CR995
        r'æ–œå¡ç¼–å·[:\s]+([A-Z0-9\-/#\s]+)',           # æ–œå¡ç¼–å·: 11SW-D/CR995
        r'Slope\s+No\.?[:\s]+([A-Z0-9\-/#\s]+)',      # Slope No: 11SW-D/CR995
    ]
    
    for pattern in chinese_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_rcc(match.group(1))
            if slope_no:
                print(f"âœ… ä»æ–œå¡ç¼–å·æå–: {slope_no}")
                return slope_no
    
    # æ¨¡å¼4: é€šç”¨æ–œå¡ç¼–å·æ ¼å¼åŒ¹é…
    general_patterns = [
        r'(\d+SW[-\s]*[A-Z][-\s]*/?[A-Z]*\d+)',        # 11SW-D/CR995
        r'([A-Z0-9]+SW[-\s]*[A-Z][-\s]*/?[A-Z]*\d+)',  # é€šç”¨æ ¼å¼
        r'(\d{2}[A-Z]{2}[-\s]*[A-Z][-\s]*/?[A-Z]*\d+)', # 11SW-D/995
    ]
    
    for pattern in general_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_rcc(match.group(1))
            if slope_no:
                print(f"âœ… ä»é€šç”¨æ ¼å¼æå–æ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    print("âš ï¸ RCCæœªæ‰¾åˆ°æ–œå¡ç¼–å·")
    return ""


def clean_slope_number_rcc(slope_text: str) -> str:
    """
    æ¸…ç†RCCæ–œå¡ç¼–å·ï¼Œå»é™¤å¹²æ‰°ä¿¡æ¯
    
    Args:
        slope_text (str): åŸå§‹æ–œå¡ç¼–å·æ–‡æœ¬
        
    Returns:
        str: æ¸…ç†åçš„æ–œå¡ç¼–å·
    """
    if not slope_text:
        return ""
    
    # å»é™¤#å·ã€ç©ºæ ¼å’Œå…¶ä»–å¹²æ‰°å­—ç¬¦
    cleaned = re.sub(r'[#\s]+', '', slope_text.strip())
    
    # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œæ–œæ 
    cleaned = re.sub(r'[^A-Z0-9\-/]', '', cleaned.upper())
    
    # ä¿®æ­£OCRé”™è¯¯
    if cleaned.startswith('LSW') or cleaned.startswith('ISW') or cleaned.startswith('JSW'):
        cleaned = '11SW' + cleaned[3:]
    elif cleaned.startswith('lSW') or cleaned.startswith('iSW') or cleaned.startswith('jSW'):
        cleaned = '11SW' + cleaned[3:]
    elif cleaned.startswith('1SW') and len(cleaned) > 3:
        # å¤„ç† 1SW-D/CR995 -> 11SW-D/CR995
        cleaned = '11SW' + cleaned[3:]
    
    # ç¡®ä¿æ ¼å¼æ­£ç¡®
    if cleaned and len(cleaned) >= 4:
        # æ ‡å‡†åŒ–è¿å­—ç¬¦æ ¼å¼
        if 'SW' in cleaned and '-' not in cleaned:
            # åœ¨SWåæ·»åŠ è¿å­—ç¬¦ï¼Œå¦‚11SWD -> 11SW-D
            cleaned = re.sub(r'(SW)([A-Z])', r'\1-\2', cleaned)
    
    return cleaned


def format_slope_number_rcc(slope_no: str) -> str:
    """
    æ ¼å¼åŒ–RCCæ–œå¡ç¼–å·ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    
    Args:
        slope_no (str): åŸå§‹æ–œå¡ç¼–å·
        
    Returns:
        str: æ ¼å¼åŒ–åçš„æ–œå¡ç¼–å·
    """
    if not slope_no:
        return ""
    
    # å»é™¤#å·ã€ç©ºæ ¼å’Œå…¶ä»–å¹²æ‰°å­—ç¬¦
    cleaned = re.sub(r'[#\s]+', '', slope_no.strip())
    
    # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œæ–œæ 
    cleaned = re.sub(r'[^A-Z0-9\-/]', '', cleaned.upper())
    
    # è½¬æ¢æ ¼å¼ï¼š11SWB/F199 -> 11SW-B/F199
    if 'SWB' in cleaned and 'SW-B' not in cleaned:
        cleaned = cleaned.replace('SWB', 'SW-B')
    elif 'SWD' in cleaned and 'SW-D' not in cleaned:
        cleaned = cleaned.replace('SWD', 'SW-D')
    elif 'SWC' in cleaned and 'SW-C' not in cleaned:
        cleaned = cleaned.replace('SWC', 'SW-C')
    elif 'SWA' in cleaned and 'SW-A' not in cleaned:
        cleaned = cleaned.replace('SWA', 'SW-A')
    
    return cleaned


def extract_location_info(content: str) -> str:
    """
    æå–ä½ç½®ä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: ä½ç½®ä¿¡æ¯
    """
    # ä¼˜å…ˆåŒ¹é…Addresså­—æ®µï¼ˆæ”¯æŒOCRè¯†åˆ«çš„æ ¼å¼ï¼‰
    address_patterns = [
        r'Address[:\s]+([A-Za-z0-9\s,.-]+?)(?=\s*\(slope\s+no)',  # Address: Broadwood Road Mini Park(slope no
        r'Address[:\s]+([A-Za-z0-9\s,.-]+?)(?=\s+Contact\s+person)',  # Address: å®é™…åœ°å€ Contact person
        r'åœ°å€[:\s]+([A-Za-z0-9\s,.-]+?)(?=\s+Contact\s+person)',     # åœ°å€: å®é™…åœ°å€ Contact person
    ]
    
    for pattern in address_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            address = match.group(1).strip()
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆåœ°å€ä¿¡æ¯
            if address and not any(keyword in address.lower() for keyword in ['contact', 'person', 'title', 'mr', 'mobile']):
                return address
    
    # æŸ¥æ‰¾åŒ…å«GARDENã€BOTANICALç­‰å…³é”®è¯çš„ä½ç½®ä¿¡æ¯
    garden_patterns = [
        r'([A-Z\s]+GARDEN[A-Z\s]*)',  # ZOOLOGICAL AND BOTANICAL GARDEN
        r'([A-Z\s]+BOTANICAL[A-Z\s]*)',  # BOTANICAL GARDEN
        r'([A-Z\s]+ZOOLOGICAL[A-Z\s]*)',  # ZOOLOGICAL GARDEN
    ]
    
    for pattern in garden_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            garden_name = match.group(1).strip()
            if len(garden_name) > 10:  # ç¡®ä¿æ˜¯å®Œæ•´çš„åœ°å
                return garden_name
    
    # å¤‡é€‰ï¼šLocation Code
    location_code_match = re.search(r'Location\s+Code[:\s]+([A-Z0-9]+)', content, re.IGNORECASE)
    if location_code_match:
        return f"Location Code: {location_code_match.group(1)}"
    
    # å¤‡é€‰ä½ç½®ä¿¡æ¯
    patterns = [
        r'ä½ç½®[ï¼š:]\s*([^\n]+)',        # ä½ç½®: XXX
        r'Location[ï¼š:]\s*([^\n]+)',    # Location: XXX
        r'åœ°é»[ï¼š:]\s*([^\n]+)',        # åœ°é»: XXX
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            return match.group(1).strip()
    
    return ""


def extract_nature_of_request(content: str) -> str:
    """
    æå–è¯·æ±‚æ€§è´¨
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: è¯·æ±‚æ€§è´¨æ‘˜è¦
    """
    # åŒ¹é…è¯·æ±‚æ€§è´¨
    patterns = [
        r'æ€§è³ª[ï¼š:]\s*([^\n]+)',        # æ€§è³ª: XXX
        r'Nature[ï¼š:]\s*([^\n]+)',      # Nature: XXX
        r'å…§å®¹[ï¼š:]\s*([^\n]+)',       # å…§å®¹: XXX
        r'Description[ï¼š:]\s*([^\n]+)', # Description: XXX
    ]
    
    for pattern in patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            desc = match.group(1).strip()
            return desc[:100] + "..." if len(desc) > 100 else desc
    
    return ""


# æ³¨æ„ï¼šget_location_from_slope_no å‡½æ•°ç°åœ¨ä» slope_location_mapper æ¨¡å—å¯¼å…¥


def extract_case_data_from_pdf(pdf_path: str) -> Dict[str, Any]:
    """
    ä»RCC PDFæ–‡ä»¶ä¸­æå–æ‰€æœ‰æ¡ˆä»¶æ•°æ®ï¼Œè¿”å›å­—å…¸æ ¼å¼
    
    è¿™æ˜¯ä¸»è¦çš„RCCæ•°æ®æå–å‡½æ•°ï¼ŒæŒ‰ç…§A-Qå­—æ®µè§„åˆ™æå–ï¼š
    - A: æ¡ˆä»¶æ¥æ”¶æ—¥æœŸ
    - B: æ¥æº (RCC)
    - C: 1823æ¡ˆä»¶å· (RCCæ¡ˆä»¶ç¼–å·)
    - D: æ¡ˆä»¶ç±»å‹ (æ ¹æ®å†…å®¹åˆ¤æ–­)
    - E: æ¥ç”µäººå§“å (è”ç³»äºº)
    - F: è”ç³»ç”µè¯
    - G: æ–œå¡ç¼–å·
    - H: ä½ç½® (ä»Excelæ•°æ®è·å–)
    - I: è¯·æ±‚æ€§è´¨æ‘˜è¦
    - J: äº‹é¡¹ä¸»é¢˜
    - K: 10å¤©è§„åˆ™æˆªæ­¢æ—¥æœŸ (A+10å¤©)
    - L: ICCä¸´æ—¶å›å¤æˆªæ­¢æ—¥æœŸ (ä¸é€‚ç”¨)
    - M: ICCæœ€ç»ˆå›å¤æˆªæ­¢æ—¥æœŸ (ä¸é€‚ç”¨)
    - N: å·¥ç¨‹å®Œæˆæˆªæ­¢æ—¥æœŸ (å–å†³äºD)
    - O1: å‘ç»™æ‰¿åŒ…å•†çš„ä¼ çœŸæ—¥æœŸ (é€šå¸¸åŒA)
    - O2: é‚®ä»¶å‘é€æ—¶é—´ (ä¸é€‚ç”¨)
    - P: ä¼ çœŸé¡µæ•° (PDFé¡µæ•°)
    - Q: æ¡ˆä»¶è¯¦æƒ…
    
    Args:
        pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        Dict[str, Any]: åŒ…å«æ‰€æœ‰A-Qå­—æ®µçš„å­—å…¸
    """
    result = {}
    
    # æå–PDFå†…å®¹
    content = extract_content_with_multiple_methods(pdf_path)
    
    if not content:
        print("è­¦å‘Š: æ— æ³•ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ï¼Œå¯èƒ½æ˜¯æ‰«æä»¶æˆ–åŠ å¯†æ–‡ä»¶")
        print("æç¤º: è¯·ä½¿ç”¨OCRå·¥å…·å°†PDFè½¬æ¢ä¸ºæ–‡æœ¬ï¼Œæˆ–æä¾›å¯ç¼–è¾‘çš„PDFæ–‡ä»¶")
        
        # å³ä½¿æ— æ³•æå–æ–‡æœ¬ï¼Œä¹Ÿæä¾›ä¸€äº›åŸºæœ¬ä¿¡æ¯
        result = {}
        
        # ä»æ–‡ä»¶åæå–åŸºæœ¬ä¿¡æ¯
        # B: æ¥æºï¼ˆæ™ºèƒ½åˆ†ç±»ï¼‰
        result['B_source'] = classify_source_smart(
            file_path=pdf_path, 
            content="", 
            email_content=None, 
            file_type='pdf'
        )
        
        filename = os.path.basename(pdf_path)
        # å°è¯•ä»æ–‡ä»¶åæå–æ¡ˆä»¶ç¼–å·
        result['C_case_number'] = extract_rcc_case_number("", pdf_path)
        
        # è®¾ç½®é»˜è®¤å€¼
        result['A_date_received'] = ""
        result['D_type'] = "General"
        result['E_caller_name'] = ""
        result['F_contact_no'] = ""
        result['G_slope_no'] = ""
        result['H_location'] = ""
        result['I_nature_of_request'] = "RCCæ¡ˆä»¶å¤„ç† - æ— æ³•æå–å…·ä½“è¯·æ±‚å†…å®¹"
        result['J_subject_matter'] = "Others"
        result['K_10day_rule_due_date'] = ""
        result['L_icc_interim_due'] = ""
        result['M_icc_final_due'] = ""
        result['N_works_completion_due'] = ""
        result['O1_fax_to_contractor'] = ""
        result['O2_email_send_time'] = ""
        
        # è·å–PDFé¡µæ•°
        try:
            with pdfplumber.open(pdf_path) as pdf:
                result['P_fax_pages'] = str(len(pdf.pages))
        except:
            result['P_fax_pages'] = ""
        
        result['Q_case_details'] = f"RCCæ¡ˆä»¶å¤„ç† - æ–‡ä»¶: {filename} (æ— æ³•æå–æ–‡æœ¬å†…å®¹)"
        
        return result
    
    # A: æ¡ˆä»¶æ¥æ”¶æ—¥æœŸ
    date_str = extract_date_from_content(content)
    result['A_date_received'] = format_date(parse_date(date_str))
    A_date = parse_date(date_str)
    
    # B: æ¥æºï¼ˆæ™ºèƒ½åˆ†ç±»ï¼‰
    result['B_source'] = classify_source_smart(
        file_path=pdf_path, 
        content=content, 
        email_content=None, 
        file_type='pdf'
    )
    
    # C: æ¡ˆä»¶ç¼–å· (RCCæ¡ˆä»¶ç¼–å·ï¼Œä¼˜å…ˆä»æ–‡ä»¶åæå–)
    result['C_case_number'] = extract_rcc_case_number(content, pdf_path)
    
    # D: æ¡ˆä»¶ç±»å‹ (ä½¿ç”¨AIåˆ†ç±»)
    try:
        print("ğŸ¤– RCCä½¿ç”¨AIåˆ†ç±»æ¡ˆä»¶ç±»å‹...")
        case_data_for_ai = {
            'I_nature_of_request': result.get('I_nature_of_request', ''),
            'J_subject_matter': result.get('J_subject_matter', ''),
            'Q_case_details': result.get('Q_case_details', ''),
            'B_source': result.get('B_source', ''),
            'G_slope_no': result.get('G_slope_no', ''),
            'F_contact_no': result.get('F_contact_no', ''),
            'content': content
        }
        ai_result = classify_case_type_ai(case_data_for_ai)
        result['D_type'] = ai_result.get('predicted_type', 'General')
        print(f"âœ… RCC AIåˆ†ç±»å®Œæˆ: {result['D_type']} (ç½®ä¿¡åº¦: {ai_result.get('confidence', 0):.2f})")
    except Exception as e:
        print(f"âš ï¸ RCC AIåˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
        # ä¼ ç»Ÿåˆ†ç±»æ–¹æ³•ä½œä¸ºå¤‡ç”¨
        if "urgent" in content.lower() or "ç´§æ€¥" in content:
            result['D_type'] = "Urgent"
        elif "emergency" in content.lower() or "ç´§æ€¥" in content:
            result['D_type'] = "Emergency"
        else:
            result['D_type'] = "General"
    
    # E: æ¥ç”µäººå§“åï¼›F: è”ç³»ç”µè¯
    result['E_caller_name'], result['F_contact_no'] = extract_contact_info(content)
    
    # G: æ–œå¡ç¼–å·
    result['G_slope_no'] = extract_slope_number(content)
    
    # H: ä½ç½® (ä¼˜å…ˆä»Addresså­—æ®µè·å–ï¼Œå¦åˆ™ä»Excelæ•°æ®è·å–)
    address_location = extract_location_info(content)
    if address_location:
        result['H_location'] = address_location
    else:
        result['H_location'] = get_location_from_slope_no(result['G_slope_no'])
    
    # I: è¯·æ±‚æ€§è´¨æ‘˜è¦ (ä½¿ç”¨AIä»PDFå†…å®¹ç”Ÿæˆå…·ä½“è¯·æ±‚æ‘˜è¦)
    try:
        print("ğŸ¤– RCCä½¿ç”¨AIç”Ÿæˆè¯·æ±‚æ‘˜è¦...")
        ai_summary = generate_ai_request_summary(content, None, 'pdf')
        result['I_nature_of_request'] = ai_summary
        print(f"âœ… RCC AIè¯·æ±‚æ‘˜è¦ç”ŸæˆæˆåŠŸ: {ai_summary}")
    except Exception as e:
        print(f"âš ï¸ RCC AIæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
        # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨åŸæœ‰çš„è¯·æ±‚æ€§è´¨æå–
        result['I_nature_of_request'] = extract_nature_of_request(content)
    
    # J: äº‹é¡¹ä¸»é¢˜ (ä½¿ç”¨AIåˆ†ç±»å™¨)
    try:
        print("ğŸ¤– RCCä½¿ç”¨AIåˆ†ç±»ä¸»é¢˜...")
        subject_data_for_ai = {
            'I_nature_of_request': result.get('I_nature_of_request', ''),
            'J_subject_matter': "RCCæ¡ˆä»¶å¤„ç†",
            'Q_case_details': result.get('Q_case_details', ''),
            'content': content
        }
        ai_subject_result = classify_subject_matter_ai(subject_data_for_ai)
        result['J_subject_matter'] = ai_subject_result.get('predicted_category', 'Others')
        print(f"âœ… RCCä¸»é¢˜åˆ†ç±»å®Œæˆ: {result['J_subject_matter']} (ç½®ä¿¡åº¦: {ai_subject_result.get('confidence', 0):.2f})")
    except Exception as e:
        print(f"âš ï¸ RCCä¸»é¢˜åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: {e}")
        result['J_subject_matter'] = "Others"
    
    # K: 10å¤©è§„åˆ™æˆªæ­¢æ—¥æœŸ (A+10å¤©)
    result['K_10day_rule_due_date'] = calculate_due_date(A_date, 10)
    
    # L: ICCä¸´æ—¶å›å¤æˆªæ­¢æ—¥æœŸ (A+10ä¸ªæ—¥å†æ—¥)
    result['L_icc_interim_due'] = calculate_due_date(A_date, 10)
    
    # M: ICCæœ€ç»ˆå›å¤æˆªæ­¢æ—¥æœŸ (A+21ä¸ªæ—¥å†æ—¥)
    result['M_icc_final_due'] = calculate_due_date(A_date, 21)
    
    # N: å·¥ç¨‹å®Œæˆæˆªæ­¢æ—¥æœŸ (å–å†³äºD)
    days_map = {"Emergency": 1, "Urgent": 3, "General": 12}
    result['N_works_completion_due'] = calculate_due_date(A_date, days_map.get(result['D_type'], 0))
    
    # O1: å‘ç»™æ‰¿åŒ…å•†çš„ä¼ çœŸæ—¥æœŸ (ä»…æ—¥æœŸéƒ¨åˆ†ï¼Œé€šå¸¸åŒA)
    result['O1_fax_to_contractor'] = A_date.strftime("%Y-%m-%d") if A_date else ""
    
    # O2: é‚®ä»¶å‘é€æ—¶é—´ (RCCä¸é€‚ç”¨)
    result['O2_email_send_time'] = ""
    
    # P: ä¼ çœŸé¡µæ•° (PDFé¡µæ•°)
    try:
        with pdfplumber.open(pdf_path) as pdf:
            result['P_fax_pages'] = str(len(pdf.pages))
    except:
        result['P_fax_pages'] = ""
    
    # Q: æ¡ˆä»¶è¯¦æƒ…
    result['Q_case_details'] = f"RCCæ¡ˆä»¶å¤„ç† - {result['I_nature_of_request']}"
    
    return result
