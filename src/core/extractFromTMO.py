"""
TMO (Tree Management Office) PDFæ•°æ®æå–æ¨¡å—

æœ¬æ¨¡å—è´Ÿè´£ä»TMOçš„PDFæ–‡ä»¶ä¸­æå–SRRæ¡ˆä»¶æ•°æ®ï¼Œä¸»è¦å¤„ç†ASDå¼€å¤´çš„PDFæ–‡ä»¶ã€‚
åŸºäºextractFromTxt.pyçš„å¤„ç†é€»è¾‘ï¼Œé’ˆå¯¹TMO PDFæ–‡ä»¶çš„ç‰¹æ®Šç»“æ„è¿›è¡Œé€‚é…ã€‚

TMO PDFæ–‡ä»¶ç»“æ„ç‰¹ç‚¹ï¼š
- Date of Referral å¯¹åº” A_date_received
- From å­—æ®µå¯¹åº” B_source
- TMO Ref. å¯¹åº”æ¡ˆä»¶ç¼–å·
- åŒ…å«æ£€æŸ¥å‘˜ä¿¡æ¯å’Œè”ç³»æ–¹å¼
- æœ‰å…·ä½“çš„æ£€æŸ¥é¡¹ç›®å’Œè¯„è®º

AIå¢å¼ºåŠŸèƒ½ï¼š
- CNNå›¾åƒé¢„å¤„ç†
- å¤šå¼•æ“OCRèåˆ
- æ™ºèƒ½æ–‡æœ¬æ¸…ç†å’Œé”™è¯¯çº æ­£
- è‡ªé€‚åº”æ ¼å¼è¯†åˆ«

ä½œè€…: Project3 Team
ç‰ˆæœ¬: 2.0 (AIå¢å¼ºç‰ˆ)
"""
import re
import pdfplumber
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, Tuple, Dict, Any
import os
import PyPDF2
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai.ai_case_type_classifier import classify_case_type_ai
from ai.ai_subject_matter_classifier import classify_subject_matter_ai
from ai.ai_request_summarizer import generate_ai_request_summary
from utils.slope_location_mapper import get_location_from_slope_no
from utils.source_classifier import classify_source_smart


def extract_text_from_pdf_fast(pdf_path: str) -> str:
    """
    å¿«é€ŸPDFæ–‡æœ¬æå–ï¼Œä¼˜å…ˆé€Ÿåº¦
    """
    content = ""
    
    # æ–¹æ³•1: ä½¿ç”¨pdfplumber (é€šå¸¸æœ€å¿«)
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    content += page_text + "\n"
        if content.strip():
            print(f"âœ… pdfplumberå¿«é€Ÿæå–æˆåŠŸ: {len(content)}å­—ç¬¦")
            return content
    except Exception as e:
        print(f"âš ï¸ pdfplumberæå–å¤±è´¥: {e}")
    
    # æ–¹æ³•2: ä½¿ç”¨PyPDF2 (å¤‡é€‰)
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                page_text = page.extract_text()
                if page_text:
                    content += page_text + "\n"
        if content.strip():
            print(f"âœ… PyPDF2å¿«é€Ÿæå–æˆåŠŸ: {len(content)}å­—ç¬¦")
            return content
    except Exception as e:
        print(f"âš ï¸ PyPDF2æå–å¤±è´¥: {e}")
    
    print("âš ï¸ å¿«é€ŸPDFæå–å¤±è´¥ï¼Œå›é€€åˆ°AIå¢å¼ºå¤„ç†")
    # å›é€€åˆ°AIå¢å¼ºå¤„ç†
    try:
        from ai_enhanced_processor import get_ai_enhanced_content
        return get_ai_enhanced_content(pdf_path)
    except Exception as e:
        print(f"âš ï¸ AIå¢å¼ºå¤„ç†ä¹Ÿå¤±è´¥: {e}")
        return ""


def parse_date(date_str: str) -> Optional[datetime]:
    """
    è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡ï¼ˆç”¨äºè®¡ç®—ï¼‰ï¼Œå¤±è´¥è¿”å›None
    
    Args:
        date_str (str): æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        
    Returns:
        Optional[datetime]: è§£ææˆåŠŸè¿”å›datetimeå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
    """
    if not date_str:
        return None
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    date_formats = [
        "%d %B %Y",      # "21 January 2025"
        "%Y-%m-%d",      # "2025-01-21"
        "%d/%m/%Y",      # "21/01/2025"
        "%d-%m-%Y",      # "21-01-2025"
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except ValueError:
            continue
    
    return None


def format_date(dt: Optional[datetime]) -> str:
    """
    å°†datetimeå¯¹è±¡æ ¼å¼åŒ–ä¸ºdd-MMM-yyyyæ ¼å¼ï¼ŒNoneè¿”å›ç©º
    
    Args:
        dt (Optional[datetime]): è¦æ ¼å¼åŒ–çš„datetimeå¯¹è±¡
        
    Returns:
        str: dd-MMM-yyyyæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚ "15-Jan-2024"
    """
    return dt.strftime("%d-%b-%Y") if dt else ""


def calculate_due_date(base_date: Optional[datetime], days: int) -> str:
    """
    è®¡ç®—åŸºå‡†æ—¥æœŸåŠ dayså¤©åçš„æ—¥æœŸï¼Œè¿”å›ISOå­—ç¬¦ä¸²
    
    Args:
        base_date (Optional[datetime]): åŸºå‡†æ—¥æœŸ
        days (int): è¦æ·»åŠ çš„å¤©æ•°
        
    Returns:
        str: è®¡ç®—åçš„æ—¥æœŸISOå­—ç¬¦ä¸²
    """
    if not base_date:
        return ""
    return format_date(base_date + timedelta(days=days))


def extract_tmo_reference(content: str) -> str:
    """
    æå–TMOå‚è€ƒç¼–å·
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: TMOå‚è€ƒç¼–å·
    """
    # åŒ¹é… "TMO Ref. ASD-WC-20250089-PP" æ ¼å¼
    match = re.search(r'TMO Ref\.\s*([A-Z0-9\-]+)', content)
    return match.group(1).strip() if match else ""


def extract_referral_date(content: str) -> str:
    """
    æå–è½¬ä»‹æ—¥æœŸ (Date of Referral)
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: è½¬ä»‹æ—¥æœŸ
    """
    # åŒ¹é… "Date of Referral 21 January 2025" æ ¼å¼
    # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåªåŒ¹é…æ—¥æœŸéƒ¨åˆ†
    match = re.search(r'Date of Referral\s+(\d{1,2}\s+\w+\s+\d{4})', content)
    if match:
        date_str = match.group(1).strip()
        parsed_date = parse_date(date_str)
        return format_date(parsed_date)
    return ""


def extract_source_from(content: str) -> str:
    """
    æå–æ¥æºä¿¡æ¯ (Fromå­—æ®µ)
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: æ¥æºä¿¡æ¯
    """
    # åŒ¹é… "From Tree Management Office (TMO)" æ ¼å¼
    match = re.search(r'From\s+([^\n]+)', content)
    if match:
        source = match.group(1).strip()
        # ç®€åŒ–æ¥æºä¿¡æ¯
        if "Tree Management Office" in source or "TMO" in source:
            return "TMO"
        return source
    return ""


def extract_inspection_officers(content: str) -> Tuple[str, str]:
    """
    æå–æ£€æŸ¥å‘˜ä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        Tuple[str, str]: (æ£€æŸ¥å‘˜å§“å, è”ç³»æ–¹å¼)
    """
    # åŒ¹é…æ£€æŸ¥å‘˜ä¿¡æ¯ - ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…å®é™…æ ¼å¼
    # å®é™…æ ¼å¼: "Inspection Ms. Jennifer CHEUNG, FdO(TM)9"
    officer_match = re.search(r'Inspection\s+([^\n]+?)(?=\s+Officer|\s+Attn\.|$)', content, re.DOTALL)
    contact_match = re.search(r'Contact\s+([^\n]+)', content)
    
    officers = ""
    contact = ""
    
    if officer_match:
        officers = officer_match.group(1).strip()
        # æ¸…ç†æ ¼å¼ï¼Œæå–å§“å
        officers = re.sub(r'\s+', ' ', officers)
        # åªä¿ç•™å§“åéƒ¨åˆ†ï¼Œå»æ‰èŒä½ä¿¡æ¯
        officers = re.sub(r'\s*FdO\(TM\)\d+.*', '', officers).strip()
        # è¿›ä¸€æ­¥æ¸…ç†ï¼Œåªä¿ç•™å§“å
        officers = re.sub(r'\s*Ms\.\s*', 'Ms. ', officers)
        officers = re.sub(r'\s*Mr\.\s*', 'Mr. ', officers)
    
    if contact_match:
        contact = contact_match.group(1).strip()
    
    return officers, contact


def extract_district(content: str) -> str:
    """
    æå–åœ°åŒºä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: åœ°åŒºä¿¡æ¯
    """
    # åŒ¹é… "District Wan Chai" æ ¼å¼
    match = re.search(r'District\s+([^\n]+)', content)
    return match.group(1).strip() if match else ""


def extract_form_reference(content: str) -> str:
    """
    æå–Form 2å‚è€ƒç¼–å·
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: Form 2å‚è€ƒç¼–å·
    """
    # åŒ¹é… "Form 2 ref. no. form2-11SWB/F199-20241028-002" æ ¼å¼
    match = re.search(r'Form 2 ref\.\s+no\.\s+([^\n]+)', content)
    return match.group(1).strip() if match else ""


def extract_slope_no_from_form_ref(content: str) -> str:
    """
    ä»TMOå†…å®¹ä¸­æå–æ–œå¡ç¼–å·ï¼Œæ”¯æŒå¤šç§æ¨¡å¼
    
    æ”¯æŒçš„æå–æ¨¡å¼ï¼š
    1. slope.no åé¢çš„å†…å®¹
    2. Form 2 ref. no åé¢çš„å†…å®¹ä¸­æå–
    3. æ–œå¡ç¼–å· åé¢çš„å†…å®¹
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: æå–å¹¶æ¸…ç†åçš„æ–œå¡ç¼–å·
    """
    print("ğŸ” TMOå¼€å§‹æå–æ–œå¡ç¼–å·...")
    
    # æ¨¡å¼1: slope.no åé¢çš„å†…å®¹
    slope_patterns = [
        r'slope\.?\s*no\.?\s*[:\s]+([A-Z0-9\-/#\s]+)',  # slope.no: 11SW-B/F199
        r'slope\s+no\.?\s*[:\s]+([A-Z0-9\-/#\s]+)',     # slope no: 11SW-B/F199
        r'slope\s*[:\s]+([A-Z0-9\-/#\s]+)',             # slope: 11SW-B/F199
    ]
    
    for pattern in slope_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_tmo(match.group(1))
            if slope_no:
                print(f"âœ… ä»slope.noæå–æ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    # æ¨¡å¼2: Form 2 ref. no åé¢çš„å†…å®¹ä¸­æå–
    form_ref = extract_form_reference(content)
    if form_ref:
        # ä»form2-11SWB/F199-20241028-002ä¸­æå–11SWB/F199éƒ¨åˆ†
        slope_match = re.search(r'form2-([A-Z0-9/#\s]+)', form_ref, re.IGNORECASE)
        if slope_match:
            slope_part = slope_match.group(1).upper()
            slope_no = format_slope_number_tmo(slope_part)
            if slope_no:
                print(f"âœ… ä»Form 2 ref. noæå–æ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    # æ¨¡å¼3: æ–œå¡ç¼–å· åé¢çš„å†…å®¹
    chinese_patterns = [
        r'æ–œå¡ç¼–å·[:\s]+([A-Z0-9\-/#\s]+)',
        r'æ–œå¡ç·¨è™Ÿ[:\s]+([A-Z0-9\-/#\s]+)',
        r'æ–œå¡[:\s]+([A-Z0-9\-/#\s]+)',
    ]
    
    for pattern in chinese_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_tmo(match.group(1))
            if slope_no:
                print(f"âœ… ä»æ–œå¡ç¼–å·æå–: {slope_no}")
                return slope_no
    
    print("âš ï¸ TMOæœªæ‰¾åˆ°æ–œå¡ç¼–å·")
    return ""


def clean_slope_number_tmo(slope_text: str) -> str:
    """
    æ¸…ç†TMOæ–œå¡ç¼–å·ï¼Œå»é™¤å¹²æ‰°ä¿¡æ¯
    
    Args:
        slope_text (str): åŸå§‹æ–œå¡ç¼–å·æ–‡æœ¬
        
    Returns:
        str: æ¸…ç†åçš„æ–œå¡ç¼–å·
    """
    if not slope_text:
        return ""
    
    # å»é™¤#å·ã€ç©ºæ ¼å’Œå…¶ä»–å¹²æ‰°å­—ç¬¦
    cleaned = re.sub(r'[#\s]+', '', slope_text.strip())
    
    # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œæ–œæ 
    cleaned = re.sub(r'[^A-Z0-9\-/]', '', cleaned.upper())
    
    # ä¿®æ­£OCRé”™è¯¯
    if cleaned.startswith('LSW') or cleaned.startswith('ISW') or cleaned.startswith('JSW'):
        cleaned = '11SW' + cleaned[3:]
    elif cleaned.startswith('lSW') or cleaned.startswith('iSW') or cleaned.startswith('jSW'):
        cleaned = '11SW' + cleaned[3:]
    elif cleaned.startswith('1SW') and len(cleaned) > 3:
        # å¤„ç† 1SW-D/CR995 -> 11SW-D/CR995
        cleaned = '11SW' + cleaned[3:]
    
    # æ ¼å¼åŒ–æ–œå¡ç¼–å·
    return format_slope_number_tmo(cleaned)


def format_slope_number_tmo(slope_no: str) -> str:
    """
    æ ¼å¼åŒ–TMOæ–œå¡ç¼–å·ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    
    Args:
        slope_no (str): åŸå§‹æ–œå¡ç¼–å·
        
    Returns:
        str: æ ¼å¼åŒ–åçš„æ–œå¡ç¼–å·
    """
    if not slope_no:
        return ""
    
    # è½¬æ¢æ ¼å¼ï¼š11SWB/F199 -> 11SW-B/F199
    if 'SWB' in slope_no and 'SW-B' not in slope_no:
        slope_no = slope_no.replace('SWB', 'SW-B')
    elif 'SWD' in slope_no and 'SW-D' not in slope_no:
        slope_no = slope_no.replace('SWD', 'SW-D')
    elif 'SWC' in slope_no and 'SW-C' not in slope_no:
        slope_no = slope_no.replace('SWC', 'SW-C')
    elif 'SWA' in slope_no and 'SW-A' not in slope_no:
        slope_no = slope_no.replace('SWA', 'SW-A')
    
    return slope_no


def extract_comments(content: str) -> str:
    """
    æå–TMOè¯„è®ºä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: è¯„è®ºä¿¡æ¯
    """
    # æŸ¥æ‰¾COMMENTS FROM TMOéƒ¨åˆ†
    comments_section = re.search(r'COMMENTS FROM TMO(.*?)(?=Tree Management Office|$)', content, re.DOTALL)
    if comments_section:
        comments = comments_section.group(1).strip()
        # æ¸…ç†æ ¼å¼
        comments = re.sub(r'\s+', ' ', comments)
        return comments[:200] + "..." if len(comments) > 200 else comments
    return ""


def extract_follow_up_actions(content: str) -> str:
    """
    æå–åç»­è¡ŒåŠ¨ä¿¡æ¯
    
    Args:
        content (str): PDFæ–‡æœ¬å†…å®¹
        
    Returns:
        str: åç»­è¡ŒåŠ¨ä¿¡æ¯
    """
    # æŸ¥æ‰¾FOLLOW-UP ACTIONSéƒ¨åˆ†
    actions_section = re.search(r'FOLLOW-UP ACTIONS(.*?)(?=Tree Management Office|$)', content, re.DOTALL)
    if actions_section:
        actions = actions_section.group(1).strip()
        # æ¸…ç†æ ¼å¼
        actions = re.sub(r'\s+', ' ', actions)
        return actions[:200] + "..." if len(actions) > 200 else actions
    return ""


# æ³¨æ„ï¼šget_location_from_slope_no å‡½æ•°ç°åœ¨ä» slope_location_mapper æ¨¡å—å¯¼å…¥


def get_ai_enhanced_content(pdf_path: str) -> str:
    """
    è·å–AIå¢å¼ºçš„PDFæ–‡æœ¬å†…å®¹
    
    Args:
        pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: AIå¢å¼ºçš„æ–‡æœ¬å†…å®¹
    """
    try:
        from ai_enhanced_processor import get_ai_enhanced_text
        
        # ä½¿ç”¨AIå¢å¼ºå¤„ç†å™¨
        enhanced_content = get_ai_enhanced_text(pdf_path, "tmo")
        
        if enhanced_content:
            print(f"âœ… TMO AIå¢å¼ºå¤„ç†æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(enhanced_content)} å­—ç¬¦")
            return enhanced_content
        else:
            print("âš ï¸ TMO AIå¢å¼ºå¤„ç†æœªè¿”å›å†…å®¹ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•")
            # å›é€€åˆ°åŸå§‹æ–¹æ³•
            return extract_text_from_pdf_traditional(pdf_path)
                
    except ImportError:
        print("âš ï¸ TMO AIå¢å¼ºå¤„ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•")
        # å›é€€åˆ°åŸå§‹æ–¹æ³•
        return extract_text_from_pdf_traditional(pdf_path)
    except Exception as e:
        print(f"âš ï¸ TMO AIå¢å¼ºå¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•")
        # å›é€€åˆ°åŸå§‹æ–¹æ³•
        return extract_text_from_pdf_traditional(pdf_path)


def extract_text_from_pdf_traditional(pdf_path: str) -> str:
    """
    ä¼ ç»ŸPDFæ–‡æœ¬æå–æ–¹æ³•ä½œä¸ºå¤‡é€‰
    """
    try:
        with pdfplumber.open(pdf_path) as pdf:
            text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            return text
    except Exception as e:
        print(f"ä¼ ç»ŸPDFæå–å¤±è´¥: {e}")
        return ""


def extract_case_data_from_pdf(pdf_path: str) -> Dict[str, Any]:
    """
    ä»TMO PDFæ–‡ä»¶ä¸­æå–æ‰€æœ‰æ¡ˆä»¶æ•°æ®ï¼Œè¿”å›å­—å…¸æ ¼å¼
    
    è¿™æ˜¯ä¸»è¦çš„TMOæ•°æ®æå–å‡½æ•°ï¼ŒæŒ‰ç…§A-Qå­—æ®µè§„åˆ™æå–ï¼š
    - A: æ¡ˆä»¶æ¥æ”¶æ—¥æœŸ (Date of Referral)
    - B: æ¥æº (Fromå­—æ®µ)
    - C: 1823æ¡ˆä»¶å· (TMO Ref.)
    - D: æ¡ˆä»¶ç±»å‹ (æ ¹æ®å†…å®¹åˆ¤æ–­)
    - E: æ¥ç”µäººå§“å (æ£€æŸ¥å‘˜)
    - F: è”ç³»ç”µè¯ (Contact)
    - G: æ–œå¡ç¼–å· (ä»å†…å®¹ä¸­æå–)
    - H: ä½ç½® (ä»Excelæ•°æ®è·å–)
    - I: è¯·æ±‚æ€§è´¨æ‘˜è¦ (è¯„è®ºä¿¡æ¯)
    - J: äº‹é¡¹ä¸»é¢˜ (Form 2ç›¸å…³)
    - K: 10å¤©è§„åˆ™æˆªæ­¢æ—¥æœŸ (A+10å¤©)
    - L: ICCä¸´æ—¶å›å¤æˆªæ­¢æ—¥æœŸ (ä¸é€‚ç”¨)
    - M: ICCæœ€ç»ˆå›å¤æˆªæ­¢æ—¥æœŸ (ä¸é€‚ç”¨)
    - N: å·¥ç¨‹å®Œæˆæˆªæ­¢æ—¥æœŸ (å–å†³äºD)
    - O1: å‘ç»™æ‰¿åŒ…å•†çš„ä¼ çœŸæ—¥æœŸ (é€šå¸¸åŒA)
    - O2: é‚®ä»¶å‘é€æ—¶é—´ (ä¸é€‚ç”¨)
    - P: ä¼ çœŸé¡µæ•° (PDFé¡µæ•°)
    - Q: æ¡ˆä»¶è¯¦æƒ… (åç»­è¡ŒåŠ¨)
    
    Args:
        pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
        
    Returns:
        Dict[str, Any]: åŒ…å«æ‰€æœ‰A-Qå­—æ®µçš„å­—å…¸
    """
    result = {}
    
    # ä¼˜å…ˆä½¿ç”¨å¿«é€Ÿæ–‡æœ¬æå–ï¼Œé¿å…AIå¢å¼ºå¤„ç†
    content = extract_text_from_pdf_fast(pdf_path)
    
    if not content:
        print("âš ï¸ æ— æ³•æå–PDFæ–‡æœ¬å†…å®¹")
        return {key: "" for key in ['A_date_received', 'B_source', 'C_case_number', 'D_type', 
                                   'E_caller_name', 'F_contact_no', 'G_slope_no', 'H_location',
                                   'I_nature_of_request', 'J_subject_matter', 'K_10day_rule_due_date',
                                   'L_icc_interim_due', 'M_icc_final_due', 'N_works_completion_due',
                                   'O1_fax_to_contractor', 'O2_email_send_time', 'P_fax_pages', 'Q_case_details']}
    
    # A: æ¡ˆä»¶æ¥æ”¶æ—¥æœŸ (Date of Referral)
    result['A_date_received'] = extract_referral_date(content)
    # éœ€è¦ä»åŸå§‹å†…å®¹ä¸­æå–æ—¥æœŸå­—ç¬¦ä¸²è¿›è¡Œè§£æ
    import re
    date_match = re.search(r'Date of Referral\s+(\d{1,2}\s+\w+\s+\d{4})', content)
    A_date = parse_date(date_match.group(1).strip()) if date_match else None
    
    # B: æ¥æºï¼ˆæ™ºèƒ½åˆ†ç±»ï¼‰
    result['B_source'] = classify_source_smart(
        file_path=pdf_path, 
        content=content, 
        email_content=None, 
        file_type='pdf'
    )
    
    # C: æ¡ˆä»¶ç¼–å· (TMOéƒ¨åˆ†æ²¡æœ‰æ¡ˆä»¶ç¼–å·)
    result['C_case_number'] = ""
    
    # D: æ¡ˆä»¶ç±»å‹ (ä½¿ç”¨AIåˆ†ç±»)
    try:
        print("ğŸ¤– TMOä½¿ç”¨AIåˆ†ç±»æ¡ˆä»¶ç±»å‹...")
        case_data_for_ai = {
            'I_nature_of_request': result.get('I_nature_of_request', ''),
            'J_subject_matter': result.get('J_subject_matter', ''),
            'Q_case_details': result.get('Q_case_details', ''),
            'B_source': result.get('B_source', ''),
            'G_slope_no': result.get('G_slope_no', ''),
            'F_contact_no': result.get('F_contact_no', ''),
            'content': content
        }
        ai_result = classify_case_type_ai(case_data_for_ai)
        result['D_type'] = ai_result.get('predicted_type', 'General')
        print(f"âœ… TMO AIåˆ†ç±»å®Œæˆ: {result['D_type']} (ç½®ä¿¡åº¦: {ai_result.get('confidence', 0):.2f})")
    except Exception as e:
        print(f"âš ï¸ TMO AIåˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
        # ä¼ ç»Ÿåˆ†ç±»æ–¹æ³•ä½œä¸ºå¤‡ç”¨
        if "urgent" in content.lower() or "ç´§æ€¥" in content:
            result['D_type'] = "Urgent"
        elif "emergency" in content.lower() or "ç´§æ€¥" in content:
            result['D_type'] = "Emergency"
        else:
            result['D_type'] = "General"
    
    # E: æ¥ç”µäººå§“åï¼›F: è”ç³»ç”µè¯ (æ£€æŸ¥å‘˜ä¿¡æ¯)
    result['E_caller_name'], result['F_contact_no'] = extract_inspection_officers(content)
    
    # G: æ–œå¡ç¼–å· (ä»Form 2 ref. no.ä¸­æå–å¹¶è½¬æ¢æ ¼å¼)
    # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œä»Form 2 ref. no.ä¸­æå–æ–œå¡ç¼–å·
    # ä¾‹å¦‚ï¼š11SWB/F199 -> 11SW-B/F199
    result['G_slope_no'] = extract_slope_no_from_form_ref(content)
    
    # H: ä½ç½® (ä»Excelæ•°æ®è·å–)
    result['H_location'] = get_location_from_slope_no(result['G_slope_no'])
    
    # I: è¯·æ±‚æ€§è´¨æ‘˜è¦ (ä½¿ç”¨AIä»PDFå†…å®¹ç”Ÿæˆå…·ä½“è¯·æ±‚æ‘˜è¦)
    try:
        print("ğŸ¤– TMOä½¿ç”¨AIç”Ÿæˆè¯·æ±‚æ‘˜è¦...")
        ai_summary = generate_ai_request_summary(content, None, 'pdf')
        result['I_nature_of_request'] = ai_summary
        print(f"âœ… TMO AIè¯·æ±‚æ‘˜è¦ç”ŸæˆæˆåŠŸ: {ai_summary}")
    except Exception as e:
        print(f"âš ï¸ TMO AIæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
        # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨åŸæœ‰çš„è¯„è®ºæå–
        result['I_nature_of_request'] = extract_comments(content)
    
    # J: äº‹é¡¹ä¸»é¢˜ (ä½¿ç”¨AIåˆ†ç±»å™¨)
    try:
        print("ğŸ¤– TMOä½¿ç”¨AIåˆ†ç±»ä¸»é¢˜...")
        subject_data_for_ai = {
            'I_nature_of_request': result.get('I_nature_of_request', ''),
            'J_subject_matter': "Tree Risk Assessment Form 2",
            'Q_case_details': result.get('Q_case_details', ''),
            'content': content
        }
        ai_subject_result = classify_subject_matter_ai(subject_data_for_ai)
        result['J_subject_matter'] = ai_subject_result.get('predicted_category', 'Tree Trimming/ Pruning')
        print(f"âœ… TMOä¸»é¢˜åˆ†ç±»å®Œæˆ: {result['J_subject_matter']} (ç½®ä¿¡åº¦: {ai_subject_result.get('confidence', 0):.2f})")
    except Exception as e:
        print(f"âš ï¸ TMOä¸»é¢˜åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: {e}")
        result['J_subject_matter'] = "Tree Trimming/ Pruning"
    
    # K: 10å¤©è§„åˆ™æˆªæ­¢æ—¥æœŸ (A+10å¤©)
    result['K_10day_rule_due_date'] = calculate_due_date(A_date, 10)
    
    # L: ICCä¸´æ—¶å›å¤æˆªæ­¢æ—¥æœŸ (A+10ä¸ªæ—¥å†æ—¥)
    result['L_icc_interim_due'] = calculate_due_date(A_date, 10)
    
    # M: ICCæœ€ç»ˆå›å¤æˆªæ­¢æ—¥æœŸ (A+21ä¸ªæ—¥å†æ—¥)
    result['M_icc_final_due'] = calculate_due_date(A_date, 21)
    
    # N: å·¥ç¨‹å®Œæˆæˆªæ­¢æ—¥æœŸ (å–å†³äºD)
    days_map = {"Emergency": 1, "Urgent": 3, "General": 12}
    result['N_works_completion_due'] = calculate_due_date(A_date, days_map.get(result['D_type'], 0))
    
    # O1: å‘ç»™æ‰¿åŒ…å•†çš„ä¼ çœŸæ—¥æœŸ (ä»…æ—¥æœŸéƒ¨åˆ†ï¼Œé€šå¸¸åŒA)
    result['O1_fax_to_contractor'] = A_date.strftime("%Y-%m-%d") if A_date else ""
    
    # O2: é‚®ä»¶å‘é€æ—¶é—´ (TMOä¸é€‚ç”¨)
    result['O2_email_send_time'] = ""
    
    # P: ä¼ çœŸé¡µæ•° (PDFé¡µæ•°)
    try:
        with pdfplumber.open(pdf_path) as pdf:
            result['P_fax_pages'] = str(len(pdf.pages))
    except:
        result['P_fax_pages'] = ""
    
    # Q: æ¡ˆä»¶è¯¦æƒ… (åç»­è¡ŒåŠ¨)
    result['Q_case_details'] = extract_follow_up_actions(content)
    
    return result
