#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIä¸»é¢˜åˆ†ç±»å™¨ - J_subject_matterå­—æ®µæ™ºèƒ½åˆ†ç±»
åŸºäºå†å²æ•°æ®å’Œè§„åˆ™è¿›è¡Œæ™ºèƒ½åˆ†ç±»ï¼Œæ”¯æŒ17ä¸ªé¢„å®šä¹‰ç±»åˆ«
"""

import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder
import numpy as np
from typing import Dict, Any, List, Tuple, Optional
import os
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.file_utils import read_file_with_encoding
from .ai_model_cache import get_cached_model, cache_model


# é¢„å®šä¹‰çš„ä¸»é¢˜ç±»åˆ«æ˜ å°„
SUBJECT_MATTER_CATEGORIES = {
    0: "Endangered Tree",
    1: "Drainage Blockage", 
    2: "Fallen Tree",
    3: "Grass Cutting",
    4: "Remove Debris",
    5: "Mosquito Breeding",
    6: "Tree Trimming/ Pruning",
    7: "Landslide",
    8: "Fallen Rock/ Boulders",
    9: "Water Seepage",
    10: "Hazardous tree",
    11: "Others",
    12: "Tree Transplantation / Felling",
    13: "Cracked slope/Wall Surface",
    14: "Repair slope fixture/furniture",
    15: "Surface erosion",
    16: "Repeated case",
    17: "Reminder for outstanding works"
}

# åå‘æ˜ å°„
CATEGORY_TO_ID = {v: k for k, v in SUBJECT_MATTER_CATEGORIES.items()}


def load_historical_subject_data(data_path: str) -> pd.DataFrame:
    """
    åŠ è½½å†å²ä¸»é¢˜åˆ†ç±»æ•°æ®
    
    Args:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        pd.DataFrame: æ¸…æ´—åçš„å†å²æ•°æ®
    """
    try:
        print(f"ğŸ“Š åŠ è½½å†å²ä¸»é¢˜æ•°æ®: {data_path}")
        
        if data_path.endswith('.csv'):
            # è¯»å–CSVæ–‡ä»¶
            csv_content = read_file_with_encoding(data_path)
            with open('temp_subject_data.csv', 'w', encoding='utf-8') as f:
                f.write(csv_content)
            df = pd.read_csv('temp_subject_data.csv')
            os.remove('temp_subject_data.csv')
        else:
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(data_path, usecols='A:AZ')
        
        print(f"âœ… åŸå§‹æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
        
        # æŸ¥æ‰¾ç›¸å…³åˆ—
        nature_col = None
        aims_col = None
        
        for col in df.columns:
            if 'nature of complaint' in col.lower():
                nature_col = col
            elif 'aims complaint type' in col.lower():
                aims_col = col
        
        if not nature_col and not aims_col:
            print("âš ï¸ æœªæ‰¾åˆ°ä¸»é¢˜ç›¸å…³åˆ—ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®")
            return pd.DataFrame()
        
        # æ¸…æ´—æ•°æ®
        cleaned_data = []
        
        # ä½¿ç”¨AIMS Complaint Typeä½œä¸ºä¸»è¦æ•°æ®æº
        if aims_col:
            aims_data = df[aims_col].dropna()
            for complaint_type in aims_data:
                if complaint_type and str(complaint_type).strip():
                    cleaned_data.append({
                        'complaint_text': str(complaint_type).strip(),
                        'source': 'AIMS'
                    })
        
        # è¡¥å……Nature of complaintæ•°æ®
        if nature_col:
            nature_data = df[nature_col].dropna()
            for nature in nature_data:
                if nature and str(nature).strip():
                    cleaned_data.append({
                        'complaint_text': str(nature).strip(),
                        'source': 'Nature'
                    })
        
        result_df = pd.DataFrame(cleaned_data)
        print(f"âœ… æ¸…æ´—åæ•°æ®: {len(result_df)} æ¡è®°å½•")
        
        return result_df
        
    except Exception as e:
        print(f"âŒ åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def create_keyword_mapping() -> Dict[str, List[str]]:
    """
    åˆ›å»ºå…³é”®è¯åˆ°ç±»åˆ«çš„æ˜ å°„
    
    Returns:
        Dict[str, List[str]]: ç±»åˆ«åˆ°å…³é”®è¯çš„æ˜ å°„
    """
    keyword_mapping = {
        "Endangered Tree": [
            "endangered tree", "å±é™©æ ‘æœ¨", "tree danger", "tree risk", "unstable tree"
        ],
        "Drainage Blockage": [
            "drainage", "blockage", "blocked drain", "æ’æ°´", "å µå¡", "drainage clearance",
            "drain block", "water block", "æ’æ°´å µå¡"
        ],
        "Fallen Tree": [
            "fallen tree", "tree fall", "å€’å¡Œæ ‘æœ¨", "fallen trees", "tree fallen",
            "tree collapse", "å€’æ ‘"
        ],
        "Grass Cutting": [
            "grass cutting", "grass cut", "trimming", "å‰²è‰", "ä¿®å‰ªè‰åª", 
            "grass maintenance", "lawn cutting"
        ],
        "Remove Debris": [
            "remove debris", "debris removal", "æ¸…ç†ç¢ç‰‡", "remove refuse", 
            "rubbish removal", "æ¸…ç†åƒåœ¾", "debris clear"
        ],
        "Mosquito Breeding": [
            "mosquito", "breeding", "èšŠè™«æ»‹ç”Ÿ", "mosquito control", "pest control",
            "insect breeding"
        ],
        "Tree Trimming/ Pruning": [
            "tree trimming", "pruning", "tree pruning", "ä¿®å‰ªæ ‘æœ¨", "tree maintenance",
            "branch cutting", "tree cut"
        ],
        "Landslide": [
            "landslide", "slope failure", "å±±æ³¥å€¾æ³»", "åœŸçŸ³æµ", "slope collapse",
            "land slip", "slope instability"
        ],
        "Fallen Rock/ Boulders": [
            "fallen rock", "boulder", "rock fall", "çŸ³å¤´æ‰è½", "å²©çŸ³æ»‘è½",
            "rock slide", "stone fall"
        ],
        "Water Seepage": [
            "water seepage", "seepage", "æ¸—æ°´", "water leak", "water infiltration",
            "observe water seepage", "water penetration"
        ],
        "Hazardous tree": [
            "hazardous tree", "dangerous tree", "tree hazard", "å±é™©æ ‘æœ¨",
            "unsafe tree", "tree safety"
        ],
        "Tree Transplantation / Felling": [
            "tree transplantation", "tree felling", "tree removal", "ç§»æ¤æ ‘æœ¨",
            "ç ä¼æ ‘æœ¨", "tree relocation"
        ],
        "Cracked slope/Wall Surface": [
            "crack", "cracked slope", "wall crack", "è£‚ç¼", "slope crack",
            "surface crack", "wall surface"
        ],
        "Repair slope fixture/furniture": [
            "repair", "slope fixture", "furniture", "ç»´ä¿®", "slope maintenance",
            "fixture repair", "slope repair"
        ],
        "Surface erosion": [
            "erosion", "surface erosion", "åœŸå£¤ä¾µèš€", "slope erosion",
            "surface wear", "weathering"
        ],
        "Repeated case": [
            "repeated", "repeat case", "é‡å¤æ¡ˆä¾‹", "duplicate", "recurring",
            "repeated case"
        ],
        "Reminder for outstanding works": [
            "reminder", "outstanding", "follow up", "æé†’", "æœªå®Œæˆå·¥ä½œ",
            "pending work", "outstanding work"
        ],
        "Others": [
            "others", "other", "å…¶ä»–", "miscellaneous", "general", "unspecified"
        ]
    }
    
    return keyword_mapping


class SubjectMatterClassifier:
    """ä¸»é¢˜åˆ†ç±»å™¨"""
    
    def __init__(self, historical_data_paths: List[str]):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨ï¼Œä½¿ç”¨ç¼“å­˜ä¼˜åŒ–
        
        Args:
            historical_data_paths: å†å²æ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # å°è¯•ä»ç¼“å­˜è·å–åˆ†ç±»å™¨
        cache_key = "subject_matter_classifier"
        cached_classifier = get_cached_model(cache_key)
        
        if cached_classifier:
            # ä½¿ç”¨ç¼“å­˜çš„åˆ†ç±»å™¨
            self.historical_data = cached_classifier.get('historical_data')
            self.keyword_mapping = cached_classifier.get('keyword_mapping')
            self.vectorizer = cached_classifier.get('vectorizer')
            self.model = cached_classifier.get('model')
            self.label_encoder = cached_classifier.get('label_encoder')
            print("ğŸš€ ä½¿ç”¨ç¼“å­˜çš„ä¸»é¢˜åˆ†ç±»å™¨")
            return
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ­£å¸¸åˆå§‹åŒ–
        self.historical_data = self._load_all_historical_data(historical_data_paths)
        self.keyword_mapping = create_keyword_mapping()
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', ngram_range=(1, 2))
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.label_encoder = LabelEncoder()
        self._train_model()
        
        # ç¼“å­˜åˆ†ç±»å™¨
        try:
            classifier_cache = {
                'historical_data': self.historical_data,
                'keyword_mapping': self.keyword_mapping,
                'vectorizer': self.vectorizer,
                'model': self.model,
                'label_encoder': self.label_encoder
            }
            cache_model(cache_key, classifier_cache)
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¸»é¢˜åˆ†ç±»å™¨å¤±è´¥: {e}")
    
    def _load_all_historical_data(self, data_paths: List[str]) -> pd.DataFrame:
        """åŠ è½½æ‰€æœ‰å†å²æ•°æ®"""
        all_data = []
        
        for path in data_paths:
            if os.path.exists(path):
                df = load_historical_subject_data(path)
                if not df.empty:
                    all_data.append(df)
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            print(f"âœ… æ€»å†å²æ•°æ®: {len(combined_df)} æ¡è®°å½•")
            return combined_df
        else:
            print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆå†å²æ•°æ®")
            return pd.DataFrame()
    
    def _preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬"""
        if not text:
            return ""
        
        # è½¬æ¢ä¸ºå°å†™
        text = str(text).lower()
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—å’Œç©ºæ ¼
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _map_to_standard_category(self, complaint_text: str) -> str:
        """å°†å†å²æ•°æ®æ˜ å°„åˆ°æ ‡å‡†ç±»åˆ«"""
        text_lower = complaint_text.lower()
        
        # ç›´æ¥åŒ¹é…
        for category, keywords in self.keyword_mapping.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    return category
        
        # ç‰¹æ®Šæ˜ å°„è§„åˆ™
        mapping_rules = {
            'trimming': 'Tree Trimming/ Pruning',
            'withered tree': 'Hazardous tree',
            'to observe': 'Others',
            'slope maintenance': 'Repair slope fixture/furniture',
            'drainage clearance': 'Drainage Blockage',
            'remove refuse': 'Remove Debris'
        }
        
        for pattern, category in mapping_rules.items():
            if pattern in text_lower:
                return category
        
        return "Others"
    
    def _train_model(self):
        """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
        if self.historical_data.empty:
            print("âš ï¸ æ— å†å²æ•°æ®ï¼Œä»…ä½¿ç”¨è§„åˆ™åˆ†ç±»")
            return
        
        print("ğŸ¤– è®­ç»ƒä¸»é¢˜åˆ†ç±»æ¨¡å‹...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        texts = []
        labels = []
        
        for _, row in self.historical_data.iterrows():
            complaint_text = row['complaint_text']
            processed_text = self._preprocess_text(complaint_text)
            
            if processed_text:
                # æ˜ å°„åˆ°æ ‡å‡†ç±»åˆ«
                category = self._map_to_standard_category(complaint_text)
                texts.append(processed_text)
                labels.append(category)
        
        if len(texts) < 10:
            print("âš ï¸ è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œä»…ä½¿ç”¨è§„åˆ™åˆ†ç±»")
            return
        
        # ç¼–ç æ ‡ç­¾
        encoded_labels = self.label_encoder.fit_transform(labels)
        
        # å‘é‡åŒ–æ–‡æœ¬
        X = self.vectorizer.fit_transform(texts)
        
        # åˆ†å‰²è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels
        )
        
        # è®­ç»ƒæ¨¡å‹
        self.model.fit(X_train, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.2f}")
        
        # æ˜¾ç¤ºåˆ†ç±»æŠ¥å‘Š
        try:
            target_names = self.label_encoder.classes_
            print("\næ¨¡å‹è¯„ä¼°:")
            print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))
        except Exception as e:
            print(f"\nâš ï¸ åˆ†ç±»æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            print(f"æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2f}")
    
    def _rule_based_classify(self, case_data: Dict[str, Any]) -> Tuple[Optional[str], float, str]:
        """åŸºäºè§„åˆ™çš„åˆ†ç±»"""
        # æ”¶é›†æ‰€æœ‰æ–‡æœ¬ä¿¡æ¯
        text_sources = [
            case_data.get('I_nature_of_request', ''),
            case_data.get('J_subject_matter', ''),
            case_data.get('Q_case_details', ''),
            case_data.get('content', '')
        ]
        
        combined_text = ' '.join(filter(None, text_sources)).lower()
        
        if not combined_text.strip():
            return None, 0.0, "no_content"
        
        # å…³é”®è¯åŒ¹é…è¯„åˆ†
        category_scores = {}
        
        for category, keywords in self.keyword_mapping.items():
            score = 0
            matched_keywords = []
            
            for keyword in keywords:
                if keyword.lower() in combined_text:
                    # æ ¹æ®å…³é”®è¯é‡è¦æ€§ç»™åˆ†
                    if len(keyword) > 10:  # é•¿å…³é”®è¯æ›´ç²¾ç¡®
                        score += 3
                    elif len(keyword) > 5:
                        score += 2
                    else:
                        score += 1
                    matched_keywords.append(keyword)
            
            if score > 0:
                category_scores[category] = {
                    'score': score,
                    'keywords': matched_keywords
                }
        
        if category_scores:
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç±»åˆ«
            best_category = max(category_scores.keys(), key=lambda x: category_scores[x]['score'])
            max_score = category_scores[best_category]['score']
            confidence = min(max_score / 10.0, 1.0)  # å½’ä¸€åŒ–ç½®ä¿¡åº¦
            
            return best_category, confidence, f"rule_based (keywords: {category_scores[best_category]['keywords'][:3]})"
        
        return None, 0.0, "no_match"
    
    def _ml_classify(self, case_data: Dict[str, Any]) -> Tuple[str, float, str]:
        """åŸºäºæœºå™¨å­¦ä¹ çš„åˆ†ç±»"""
        if not hasattr(self.model, 'predict'):
            return "Others", 0.3, "ml_not_available"
        
        # æ”¶é›†æ–‡æœ¬ä¿¡æ¯
        text_sources = [
            case_data.get('I_nature_of_request', ''),
            case_data.get('J_subject_matter', ''),
            case_data.get('Q_case_details', ''),
            case_data.get('content', '')
        ]
        
        combined_text = ' '.join(filter(None, text_sources))
        processed_text = self._preprocess_text(combined_text)
        
        if not processed_text:
            return "Others", 0.3, "no_text_for_ml"
        
        try:
            # å‘é‡åŒ–
            X = self.vectorizer.transform([processed_text])
            
            # é¢„æµ‹
            prediction = self.model.predict(X)[0]
            probabilities = self.model.predict_proba(X)[0]
            
            # è§£ç æ ‡ç­¾
            predicted_category = self.label_encoder.inverse_transform([prediction])[0]
            confidence = max(probabilities)
            
            return predicted_category, confidence, f"machine_learning"
            
        except Exception as e:
            print(f"âš ï¸ MLåˆ†ç±»å¤±è´¥: {e}")
            return "Others", 0.3, "ml_error"
    
    def classify(self, case_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸»åˆ†ç±»æ–¹æ³•
        
        Args:
            case_data: æ¡ˆä»¶æ•°æ®
            
        Returns:
            Dict: åˆ†ç±»ç»“æœ
        """
        print("ğŸ” å¼€å§‹ä¸»é¢˜åˆ†ç±»...")
        
        # 1. å°è¯•è§„åˆ™åˆ†ç±»
        rule_result, rule_confidence, rule_method = self._rule_based_classify(case_data)
        
        # 2. å°è¯•MLåˆ†ç±»
        ml_result, ml_confidence, ml_method = self._ml_classify(case_data)
        
        # 3. å†³ç­–é€»è¾‘
        if rule_result and rule_confidence >= 0.7:
            # é«˜ç½®ä¿¡åº¦è§„åˆ™åˆ†ç±»
            final_category = rule_result
            final_confidence = rule_confidence
            final_method = rule_method
        elif rule_result and ml_result == rule_result:
            # è§„åˆ™å’ŒMLä¸€è‡´
            final_category = rule_result
            final_confidence = (rule_confidence + ml_confidence) / 2
            final_method = f"consensus ({rule_method} + {ml_method})"
        elif ml_confidence >= 0.6:
            # é«˜ç½®ä¿¡åº¦MLåˆ†ç±»
            final_category = ml_result
            final_confidence = ml_confidence
            final_method = ml_method
        elif rule_result:
            # ä½¿ç”¨è§„åˆ™åˆ†ç±»
            final_category = rule_result
            final_confidence = rule_confidence
            final_method = rule_method
        else:
            # é»˜è®¤åˆ†ç±»
            final_category = "Others"
            final_confidence = 0.3
            final_method = "default"
        
        # è·å–ç±»åˆ«ID
        category_id = CATEGORY_TO_ID.get(final_category, 11)  # é»˜è®¤ä¸ºOthers
        
        result = {
            'predicted_category': final_category,
            'category_id': category_id,
            'confidence': final_confidence,
            'method': final_method,
            'rule_result': rule_result,
            'ml_result': ml_result
        }
        
        print(f"âœ… ä¸»é¢˜åˆ†ç±»å®Œæˆ: {final_category} (ID: {category_id}, ç½®ä¿¡åº¦: {final_confidence:.2f})")
        
        return result


def classify_subject_matter_ai(case_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    AIä¸»é¢˜åˆ†ç±»å…¥å£å‡½æ•°
    
    Args:
        case_data: æ¡ˆä»¶æ•°æ®ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - I_nature_of_request: è¯·æ±‚æ€§è´¨
            - J_subject_matter: ä¸»é¢˜äº‹é¡¹
            - Q_case_details: æ¡ˆä»¶è¯¦æƒ…
            - content: åŸå§‹å†…å®¹
            
    Returns:
        Dict: åˆ†ç±»ç»“æœ
        {
            'predicted_category': str,  # é¢„æµ‹ç±»åˆ«åç§°
            'category_id': int,         # ç±»åˆ«ID
            'confidence': float,        # ç½®ä¿¡åº¦
            'method': str,              # åˆ†ç±»æ–¹æ³•
            'rule_result': str,         # è§„åˆ™åˆ†ç±»ç»“æœ
            'ml_result': str            # MLåˆ†ç±»ç»“æœ
        }
    """
    try:
        # å†å²æ•°æ®è·¯å¾„
        historical_data_paths = [
            'depend_data/SRR data 2021-2024.csv',
            'depend_data/Slopes Complaints & Enquires Under             TC K928   4-10-2021.xlsx'
        ]
        
        # åˆ›å»ºåˆ†ç±»å™¨
        classifier = SubjectMatterClassifier(historical_data_paths)
        
        # æ‰§è¡Œåˆ†ç±»
        result = classifier.classify(case_data)
        
        return result
        
    except Exception as e:
        print(f"âŒ ä¸»é¢˜åˆ†ç±»å¤±è´¥: {e}")
        return {
            'predicted_category': 'Others',
            'category_id': 11,
            'confidence': 0.3,
            'method': 'error_fallback',
            'rule_result': None,
            'ml_result': None
        }


def test_subject_matter_classifier():
    """æµ‹è¯•ä¸»é¢˜åˆ†ç±»å™¨"""
    print("=== ä¸»é¢˜åˆ†ç±»å™¨æµ‹è¯• ===\n")
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'name': 'è‰åªä¿®å‰ª',
            'data': {
                'I_nature_of_request': 'Request for grass cutting maintenance',
                'content': 'The grass on the slope is overgrown and needs cutting'
            }
        },
        {
            'name': 'æ ‘æœ¨å€’å¡Œ',
            'data': {
                'I_nature_of_request': 'Report fallen tree on slope',
                'Q_case_details': 'A large tree has fallen and is blocking the path'
            }
        },
        {
            'name': 'æ’æ°´å µå¡',
            'data': {
                'I_nature_of_request': 'Drainage system blocked',
                'content': 'Water cannot flow properly due to blockage in drainage'
            }
        },
        {
            'name': 'å±é™©æ ‘æœ¨',
            'data': {
                'I_nature_of_request': 'Hazardous tree needs attention',
                'content': 'Tree appears unstable and poses safety risk'
            }
        },
        {
            'name': 'æ¸—æ°´é—®é¢˜',
            'data': {
                'I_nature_of_request': 'Water seepage observed',
                'content': 'Water is seeping through the slope wall'
            }
        }
    ]
    
    for test_case in test_cases:
        print(f"ğŸ“‹ æµ‹è¯•æ¡ˆä¾‹: {test_case['name']}")
        result = classify_subject_matter_ai(test_case['data'])
        
        print(f"   é¢„æµ‹ç±»åˆ«: {result['predicted_category']}")
        print(f"   ç±»åˆ«ID: {result['category_id']}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
        print(f"   åˆ†ç±»æ–¹æ³•: {result['method']}")
        print()


if __name__ == "__main__":
    test_subject_matter_classifier()
