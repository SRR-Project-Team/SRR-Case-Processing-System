"""
TMO (Tree Management Office) PDFdataextractmodule

æœ¬moduleè´Ÿè´£ä»TMOçš„PDFfileä¸­extractSRRæ¡ˆä»¶dataï¼ŒmainprocessASDå¼€å¤´çš„PDFfileã€‚
åŸºäºextractFromTxt.pyçš„processé€»è¾‘ï¼Œé’ˆå¯¹TMO PDFfileçš„ç‰¹æ®Šç»“æ„è¿›è¡Œé€‚é…ã€‚

TMO PDFfileç»“æ„ç‰¹ç‚¹ï¼š
- Date of Referral å¯¹åº” A_date_received
- From fieldå¯¹åº” B_source
- TMO Ref. å¯¹åº”æ¡ˆä»¶ç¼–å·
- åŒ…å«checkå‘˜informationå’Œè”ç³»æ–¹å¼
- æœ‰å…·ä½“çš„checké¡¹ç›®å’Œè¯„è®º

AIå¢å¼ºfunctionï¼š
- CNNå›¾åƒé¢„process
- å¤šå¼•æ“OCRèåˆ
- æ™ºèƒ½æ–‡æœ¬cleanupå’Œerrorçº æ­£
- è‡ªé€‚åº”æ ¼å¼è¯†åˆ«

ä½œè€…: Project3 Team
ç‰ˆæœ¬: 2.0 (AIå¢å¼ºç‰ˆ)
"""
import re
import pdfplumber
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, Tuple, Dict, Any
import os
import PyPDF2
import sys
import logging

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.file_utils import extract_text_from_pdf_fast

from ai.ai_case_type_classifier import classify_case_type_ai
from ai.ai_subject_matter_classifier import classify_subject_matter_ai
from ai.ai_request_summarizer import generate_ai_request_summary
from utils.slope_location_mapper import get_location_from_slope_no
from utils.source_classifier import classify_source_smart

logger = logging.getLogger(__name__)




def parse_date(date_str: str) -> Optional[datetime]:
    """
    è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºdatetimeobjectï¼ˆç”¨äºè®¡ç®—ï¼‰ï¼ŒfailedreturnNone
    
    Args:
        date_str (str): æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ”¯æŒå¤šç§æ ¼å¼
        
    Returns:
        Optional[datetime]: è§£æsuccessreturndatetimeobjectï¼ŒfailedreturnNone
    """
    if not date_str:
        return None
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼ï¼ˆåŒ…æ‹¬Vision APIå¯èƒ½è¿”å›çš„æ ¼å¼ï¼‰
    date_formats = [
        "%d-%b-%Y",      # "15-Jan-2024" (Vision APIå¸¸ç”¨æ ¼å¼)
        "%d-%B-%Y",      # "15-January-2024"
        "%d %b %Y",      # "15 Jan 2024"
        "%d %B %Y",      # "21 January 2025"
        "%Y-%m-%d",      # "2025-01-21"
        "%d/%m/%Y",      # "21/01/2025"
        "%d-%m-%Y",      # "21-01-2025"
        "%m/%d/%Y",      # "01/21/2025" (US format)
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str.strip(), fmt)
        except ValueError:
            continue
    
    return None


def format_date(dt: Optional[datetime]) -> str:
    """
    å°†datetimeobjectæ ¼å¼åŒ–ä¸ºdd-MMM-yyyyæ ¼å¼ï¼ŒNonereturnç©º
    
    Args:
        dt (Optional[datetime]): è¦æ ¼å¼åŒ–çš„datetimeobject
        
    Returns:
        str: dd-MMM-yyyyæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚ "15-Jan-2024"
    """
    return dt.strftime("%d-%b-%Y") if dt else ""


def calculate_due_date(base_date: Optional[datetime], days: int) -> str:
    """
    è®¡ç®—åŸºå‡†æ—¥æœŸåŠ dayså¤©åçš„æ—¥æœŸï¼ŒreturnISOå­—ç¬¦ä¸²
    
    Args:
        base_date (Optional[datetime]): åŸºå‡†æ—¥æœŸ
        days (int): è¦æ·»åŠ çš„å¤©æ•°
        
    Returns:
        str: è®¡ç®—åçš„æ—¥æœŸISOå­—ç¬¦ä¸²
    """
    if not base_date:
        return ""
    return format_date(base_date + timedelta(days=days))


def extract_tmo_reference(content: str) -> str:
    """
    extractTMOå‚è€ƒç¼–å·
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: TMOå‚è€ƒç¼–å·
    """
    # match "TMO Ref. ASD-WC-20250089-PP" æ ¼å¼
    match = re.search(r'TMO Ref\.\s*([A-Z0-9\-]+)', content)
    return match.group(1).strip() if match else ""


def extract_referral_date(content: str) -> str:
    """
    extractè½¬ä»‹æ—¥æœŸ (Date of Referral)
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: è½¬ä»‹æ—¥æœŸ
    """
    # match "Date of Referral 21 January 2025" æ ¼å¼
    # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™tableè¾¾å¼ï¼Œåªmatchæ—¥æœŸéƒ¨åˆ†
    match = re.search(r'Date of Referral\s+(\d{1,2}\s+\w+\s+\d{4})', content)
    if match:
        date_str = match.group(1).strip()
        parsed_date = parse_date(date_str)
        return format_date(parsed_date)
    return ""


def extract_source_from(content: str) -> str:
    """
    extractæ¥æºinformation (Fromfield)
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: æ¥æºinformation
    """
    # match "From Tree Management Office (TMO)" æ ¼å¼
    match = re.search(r'From\s+([^\n]+)', content)
    if match:
        source = match.group(1).strip()
        # ç®€åŒ–æ¥æºinformation
        if "Tree Management Office" in source or "TMO" in source:
            return "TMO"
        return source
    return ""


def extract_inspection_officers(content: str) -> Tuple[str, str]:
    """
    extractcheckå‘˜information
    
    Args:
        content (str): PDFtext content
        
    Returns:
        Tuple[str, str]: (checkå‘˜å§“å, è”ç³»æ–¹å¼)
    """
    # matchcheckå‘˜information - ä¿®å¤æ­£åˆ™tableè¾¾å¼ä»¥matchå®é™…æ ¼å¼
    # å®é™…æ ¼å¼: "Inspection Ms. Jennifer CHEUNG, FdO(TM)9"
    officer_match = re.search(r'Inspection\s+([^\n]+?)(?=\s+Officer|\s+Attn\.|$)', content, re.DOTALL)
    contact_match = re.search(r'Contact\s+([^\n]+)', content)
    
    officers = ""
    contact = ""
    
    if officer_match:
        officers = officer_match.group(1).strip()
        # cleanupæ ¼å¼ï¼Œextractå§“å
        officers = re.sub(r'\s+', ' ', officers)
        # åªä¿ç•™å§“åéƒ¨åˆ†ï¼Œå»æ‰èŒä½information
        officers = re.sub(r'\s*FdO\(TM\)\d+.*', '', officers).strip()
        # è¿›ä¸€æ­¥cleanupï¼Œåªä¿ç•™å§“å
        officers = re.sub(r'\s*Ms\.\s*', 'Ms. ', officers)
        officers = re.sub(r'\s*Mr\.\s*', 'Mr. ', officers)
    
    if contact_match:
        contact = contact_match.group(1).strip()
    
    return officers, contact


def extract_district(content: str) -> str:
    """
    extractåœ°åŒºinformation
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: åœ°åŒºinformation
    """
    # match "District Wan Chai" æ ¼å¼
    match = re.search(r'District\s+([^\n]+)', content)
    return match.group(1).strip() if match else ""


def extract_form_reference(content: str) -> str:
    """
    extractForm 2å‚è€ƒç¼–å·
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: Form 2å‚è€ƒç¼–å·
    """
    # match "Form 2 ref. no. form2-11SWB/F199-20241028-002" æ ¼å¼
    match = re.search(r'Form 2 ref\.\s+no\.\s+([^\n]+)', content)
    return match.group(1).strip() if match else ""


def extract_slope_no_from_form_ref(content: str) -> str:
    """
    ä»TMOå†…å®¹ä¸­extractæ–œå¡ç¼–å·ï¼Œæ”¯æŒå¤šç§æ¨¡å¼
    
    æ”¯æŒçš„extractæ¨¡å¼ï¼š
    1. slope.no åé¢çš„å†…å®¹
    2. Form 2 ref. no åé¢çš„å†…å®¹ä¸­extract
    3. æ–œå¡ç¼–å· åé¢çš„å†…å®¹
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: extractå¹¶æ¸…ç†åçš„æ–œå¡ç¼–å·
    """
    logger.debug("ğŸ” TMOå¼€å§‹extractæ–œå¡ç¼–å·...")
    # æ¨¡å¼4: 11SW-B/F199(0)
    slope_patterns = [
        r'\b(\d+[A-Z]+-[A-Z]+/[A-Z]+\d+(?:\(\d+\))?)\b'  # # 11SW-B/F199(0) 11SW-B/F199åŒ¹é…å¸¦ä¸å¸¦æ‹¬å·çš„ç‰ˆæœ¬
    ]

    all_slope_numbers = []

    for pattern in slope_patterns:
        # ä½¿ç”¨findallæŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            for match in matches:
                slope_no = clean_slope_number_tmo(match)
                if slope_no:
                    # å»é‡ï¼Œé¿å…é‡å¤æ·»åŠ ç›¸åŒçš„ç¼–å·
                    if slope_no not in all_slope_numbers:
                        all_slope_numbers.append(slope_no)

    if len(all_slope_numbers) == 1:
        print(f"âœ… ä»slope.noextractæ–œå¡ç¼–å·: {all_slope_numbers[0]}")
        return all_slope_numbers[0]
    # å¤šä¸ªç¼–å·ç”¨ & è¿æ¥
    elif len(all_slope_numbers) > 1:
        result = " & ".join(all_slope_numbers)
        print(f"âœ… ä»slope.noextractæ–œå¡ç¼–å·: {result}")
        return result
    # æ¨¡å¼1: slope.no åé¢çš„å†…å®¹
    slope_patterns = [
        r'slope\.?\s*no\.?\s*[:\s]+([A-Z0-9\-/#\s]+)',  # slope.no: 11SW-B/F199
        r'slope\s+no\.?\s*[:\s]+([A-Z0-9\-/#\s]+)',     # slope no: 11SW-B/F199
        r'slope\s*[:\s]+([A-Z0-9\-/#\s]+)',             # slope: 11SW-B/F199
    ]
    
    for pattern in slope_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_tmo(match.group(1))
            if slope_no:
                logger.info(f"âœ… ä»slope.noextractæ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    # æ¨¡å¼2: Form 2 ref. no åé¢çš„å†…å®¹ä¸­extract
    form_ref = extract_form_reference(content)
    if form_ref:
        # ä»form2-11SWB/F199-20241028-002ä¸­extract11SWB/F199éƒ¨åˆ†
        slope_match = re.search(r'form2-([A-Z0-9/#\s]+)', form_ref, re.IGNORECASE)
        if slope_match:
            slope_part = slope_match.group(1).upper()
            slope_no = format_slope_number_tmo(slope_part)
            if slope_no:
                logger.info(f"âœ… ä»Form 2 ref. noextractæ–œå¡ç¼–å·: {slope_no}")
                return slope_no
    
    # æ¨¡å¼3: æ–œå¡ç¼–å· åé¢çš„å†…å®¹
    chinese_patterns = [
        r'æ–œå¡ç¼–å·[:\s]+([A-Z0-9\-/#\s]+)',
        r'æ–œå¡ç·¨è™Ÿ[:\s]+([A-Z0-9\-/#\s]+)',
        r'æ–œå¡[:\s]+([A-Z0-9\-/#\s]+)',
    ]
    
    for pattern in chinese_patterns:
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            slope_no = clean_slope_number_tmo(match.group(1))
            if slope_no:
                logger.info(f"âœ… ä»æ–œå¡ç¼–å·extract: {slope_no}")
                return slope_no
    
    logger.warning("âš ï¸ TMOæœªæ‰¾åˆ°æ–œå¡ç¼–å·")
    return ""


def clean_slope_number_tmo(slope_text: str) -> str:
    """
    æ¸…ç†TMOæ–œå¡ç¼–å·ï¼Œå»é™¤å¹²æ‰°information
    
    Args:
        slope_text (str): åŸå§‹æ–œå¡ç¼–å·æ–‡æœ¬
        
    Returns:
        str: æ¸…ç†åçš„æ–œå¡ç¼–å·
    """
    if not slope_text:
        return ""
    
    # å»é™¤#å·ã€ç©ºæ ¼å’Œå…¶ä»–å¹²æ‰°å­—ç¬¦
    cleaned = re.sub(r'[#\s]+', '', slope_text.strip())
    
    # åªä¿ç•™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦å’Œæ–œæ 
    cleaned = re.sub(r'[^A-Z0-9\-/]', '', cleaned.upper())
    
    # ä¿®æ­£OCRerror
    if cleaned.startswith('LSW') or cleaned.startswith('ISW') or cleaned.startswith('JSW'):
        cleaned = '11SW' + cleaned[3:]
    elif cleaned.startswith('lSW') or cleaned.startswith('iSW') or cleaned.startswith('jSW'):
        cleaned = '11SW' + cleaned[3:]
    elif cleaned.startswith('1SW') and len(cleaned) > 3:
        # process 1SW-D/CR995 -> 11SW-D/CR995
        cleaned = '11SW' + cleaned[3:]
    
    # formatæ–œå¡ç¼–å·
    return format_slope_number_tmo(cleaned)


def format_slope_number_tmo(slope_no: str) -> str:
    """
    æ ¼å¼åŒ–TMOæ–œå¡ç¼–å·ï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    
    Args:
        slope_no (str): åŸå§‹æ–œå¡ç¼–å·
        
    Returns:
        str: æ ¼å¼åŒ–åçš„æ–œå¡ç¼–å·
    """
    if not slope_no:
        return ""
    
    # è½¬æ¢æ ¼å¼ï¼š11SWB/F199 -> 11SW-B/F199
    if 'SWB' in slope_no and 'SW-B' not in slope_no:
        slope_no = slope_no.replace('SWB', 'SW-B')
    elif 'SWD' in slope_no and 'SW-D' not in slope_no:
        slope_no = slope_no.replace('SWD', 'SW-D')
    elif 'SWC' in slope_no and 'SW-C' not in slope_no:
        slope_no = slope_no.replace('SWC', 'SW-C')
    elif 'SWA' in slope_no and 'SW-A' not in slope_no:
        slope_no = slope_no.replace('SWA', 'SW-A')
    
    return slope_no


def extract_comments(content: str) -> str:
    """
    extractTMOè¯„è®ºinformation
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: è¯„è®ºinformation
    """
    # findCOMMENTS FROM TMOéƒ¨åˆ†
    comments_section = re.search(r'COMMENTS FROM TMO(.*?)(?=Tree Management Office|$)', content, re.DOTALL)
    if comments_section:
        comments = comments_section.group(1).strip()
        # cleanupæ ¼å¼
        comments = re.sub(r'\s+', ' ', comments)
        return comments[:200] + "..." if len(comments) > 200 else comments
    return ""


def extract_follow_up_actions(content: str) -> str:
    """
    extractåç»­è¡ŒåŠ¨information
    
    Args:
        content (str): PDFtext content
        
    Returns:
        str: åç»­è¡ŒåŠ¨information
    """
    # findFOLLOW-UP ACTIONSéƒ¨åˆ†
    actions_section = re.search(r'FOLLOW-UP ACTIONS(.*?)(?=Tree Management Office|$)', content, re.DOTALL)
    if actions_section:
        actions = actions_section.group(1).strip()
        # cleanupæ ¼å¼
        actions = re.sub(r'\s+', ' ', actions)
        return actions[:200] + "..." if len(actions) > 200 else actions
    return ""


# æ³¨æ„ï¼šget_location_from_slope_no functionç°åœ¨ä» slope_location_mapper moduleimport







def extract_case_data_from_pdf(pdf_path: str) -> Dict[str, Any]:
    """
    ä»TMO PDFæ–‡ä»¶ä¸­extractæ‰€æœ‰æ¡ˆä»¶dataï¼Œreturnå­—å…¸æ ¼å¼
    
    è¿™æ˜¯ä¸»è¦çš„TMOdataextractå‡½æ•°ï¼Œä½¿ç”¨é€šç”¨çš„PDFæå–å‡½æ•°ï¼ˆåˆå¹¶äº†RCCå’ŒTMOçš„å…±åŒé€»è¾‘ï¼‰
    ä½¿ç”¨pdf2imageå°†PDFè½¬ä¸ºå›¾ç‰‡ï¼Œç„¶åä½¿ç”¨OpenAI Vision APIæå–A-Qå­—æ®µ
    
    Args:
        pdf_path (str): PDFfile path
        
    Returns:
        Dict[str, Any]: åŒ…å«æ‰€æœ‰A-Qfieldçš„å­—å…¸
    """
    # ä½¿ç”¨é€šç”¨çš„PDFæå–å‡½æ•°ï¼ˆåˆå¹¶äº†RCCå’ŒTMOçš„å…±åŒé€»è¾‘ï¼‰
    from utils.file_utils import extract_case_data_from_pdf_with_llm
    
    result = extract_case_data_from_pdf_with_llm(
        pdf_path=pdf_path,
        file_type="TMO",
        parse_date_func=parse_date,
        format_date_func=format_date,
        calculate_due_date_func=calculate_due_date,
        format_date_only_func=lambda dt: dt.strftime("%Y-%m-%d") if dt else "",
        get_location_from_slope_no_func=get_location_from_slope_no
    )
    
    print("ğŸ“„ ä½¿ç”¨ä¼ ç»ŸOCRæ–¹æ³•æå–PDFå†…å®¹...")
  
    content = extract_text_from_pdf_fast(pdf_path)

    # G: æ–œå¡ç¼–å· (ä»Form 2 ref. no.ä¸­extractå¹¶è½¬æ¢æ ¼å¼)
    # ä»Form 2 ref. no.ä¸­extractæ–œå¡ç¼–å·
    # ä¾‹å¦‚ï¼š11SWB/F199 -> 11SW-B/F199
    result['G_slope_no'] = extract_slope_no_from_form_ref(content)
    if not content:
        print("âš ï¸ æ— æ³•extractPDFtext content")
        return _get_empty_result()
    
    # å¤„ç†å®Œslope_noè¿”å›
    if result:
        return result
    
    # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ä¼ ç»ŸOCRæå–
    logger.info("ğŸ“„ ä½¿ç”¨ä¼ ç»ŸOCRæ–¹æ³•æå–PDFå†…å®¹...")
    content = extract_text_from_pdf_fast(pdf_path)
    
    if not content:
        logger.warning("âš ï¸ æ— æ³•extractPDFtext content")
        return _get_empty_result()
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    result = {}
    
    # A: æ¡ˆä»¶æ¥æ”¶æ—¥æœŸ (Date of Referral)
    result['A_date_received'] = extract_referral_date(content)
    # éœ€è¦ä»åŸå§‹å†…å®¹ä¸­extractæ—¥æœŸstringè¿›è¡Œparse
    import re
    date_match = re.search(r'Date of Referral\s+(\d{1,2}\s+\w+\s+\d{4})', content)
    A_date = parse_date(date_match.group(1).strip()) if date_match else None
    
    # B: æ¥æºï¼ˆæ ¹æ®å¤„ç†ç±»å‹ç›´æ¥åˆ†ç±»ï¼‰
    result['B_source'] = classify_source_smart(
        processing_type='tmo',
        file_path=pdf_path, 
        content=content, 
        email_content=None, 
        file_type='pdf'
    )
    
    # C: æ¡ˆä»¶ç¼–å· (TMOéƒ¨åˆ†æ²¡æœ‰æ¡ˆä»¶ç¼–å·)
    result['C_case_number'] = ""
    
    # D: æ¡ˆä»¶classå‹ (ä½¿ç”¨AIclassify)
    try:
        logger.info("ğŸ¤– TMOä½¿ç”¨AIclassifyæ¡ˆä»¶classå‹...")
        case_data_for_ai = {
            'I_nature_of_request': result.get('I_nature_of_request', ''),
            'J_subject_matter': result.get('J_subject_matter', ''),
            'Q_case_details': result.get('Q_case_details', ''),
            'B_source': result.get('B_source', ''),
            'G_slope_no': result.get('G_slope_no', ''),
            'F_contact_no': result.get('F_contact_no', ''),
            'content': content
        }
        ai_result = classify_case_type_ai(case_data_for_ai)
        result['D_type'] = ai_result.get('predicted_type', 'General')
        logger.info(f"âœ… TMO AIclassifyå®Œæˆ: {result['D_type']} (confidence: {ai_result.get('confidence', 0):.2f})")
    except Exception as e:
        logger.warning(f"âš ï¸ TMO AIclassifyfailedï¼Œä½¿ç”¨ä¼ ç»Ÿmethod: {e}")
        # ä¼ ç»Ÿclassifymethodä½œä¸ºå¤‡ç”¨
        if "urgent" in content.lower() or "ç´§æ€¥" in content:
            result['D_type'] = "Urgent"
        elif "emergency" in content.lower() or "ç´§æ€¥" in content:
            result['D_type'] = "Emergency"
        else:
            result['D_type'] = "General"
    
    # E: æ¥ç”µäººå§“åï¼›F: è”ç³»ç”µè¯ (checkå‘˜information)
    result['E_caller_name'], result['F_contact_no'] = extract_inspection_officers(content)
    
    # G: æ–œå¡ç¼–å· (ä»Form 2 ref. no.ä¸­extractå¹¶è½¬æ¢æ ¼å¼)
    # ä»Form 2 ref. no.ä¸­extractæ–œå¡ç¼–å·
    # ä¾‹å¦‚ï¼š11SWB/F199 -> 11SW-B/F199
    result['G_slope_no'] = extract_slope_no_from_form_ref(content)
    
    # H: ä½ç½® (ä»Exceldataget)
    result['H_location'] = get_location_from_slope_no(result['G_slope_no'])
    
    # I: requestæ€§è´¨æ‘˜è¦ (ä½¿ç”¨AIä»PDFå†…å®¹ç”Ÿæˆå…·ä½“requestæ‘˜è¦)
    try:
        logger.info("ğŸ¤– TMOä½¿ç”¨AIç”Ÿæˆè¯·æ±‚æ‘˜è¦...")
        ai_summary = generate_ai_request_summary(content, None, 'pdf')
        result['I_nature_of_request'] = ai_summary
        logger.info(f"âœ… TMO AIè¯·æ±‚æ‘˜è¦ç”Ÿæˆsuccess: {ai_summary}")
    except Exception as e:
        logger.warning(f"âš ï¸ TMO AIæ‘˜è¦ç”Ÿæˆfailedï¼Œä½¿ç”¨å¤‡ç”¨method: {e}")
        # å¤‡ç”¨methodï¼šä½¿ç”¨åŸæœ‰çš„è¯„è®ºextract
        result['I_nature_of_request'] = extract_comments(content)
    
    # J: äº‹é¡¹ä¸»é¢˜ (ä½¿ç”¨AIclassifyå™¨)
    try:
        logger.info("ğŸ¤– TMOä½¿ç”¨AIclassifyä¸»é¢˜...")
        subject_data_for_ai = {
            'I_nature_of_request': result.get('I_nature_of_request', ''),
            'J_subject_matter': "Tree Risk Assessment Form 2",
            'Q_case_details': result.get('Q_case_details', ''),
            'content': content
        }
        ai_subject_result = classify_subject_matter_ai(subject_data_for_ai)
        result['J_subject_matter'] = ai_subject_result.get('predicted_category', 'Tree Trimming/ Pruning')
        logger.info(f"âœ… TMOä¸»é¢˜classifyå®Œæˆ: {result['J_subject_matter']} (confidence: {ai_subject_result.get('confidence', 0):.2f})")
    except Exception as e:
        logger.warning(f"âš ï¸ TMOä¸»é¢˜classifyfailedï¼Œä½¿ç”¨é»˜è®¤: {e}")
        result['J_subject_matter'] = "Tree Trimming/ Pruning"
    
    # K: 10å¤©è§„åˆ™æˆªæ­¢æ—¥æœŸ (A+10å¤©)
    result['K_10day_rule_due_date'] = calculate_due_date(A_date, 10)
    
    # L: ICCä¸´æ—¶å›å¤æˆªæ­¢æ—¥æœŸ (A+10ä¸ªæ—¥å†æ—¥)
    result['L_icc_interim_due'] = calculate_due_date(A_date, 10)
    
    # M: ICCæœ€ç»ˆå›å¤æˆªæ­¢æ—¥æœŸ (A+21ä¸ªæ—¥å†æ—¥)
    result['M_icc_final_due'] = calculate_due_date(A_date, 21)
    
    # N: å·¥ç¨‹å®Œæˆæˆªæ­¢æ—¥æœŸ (å–å†³äºD)
    days_map = {"Emergency": 1, "Urgent": 3, "General": 12}
    result['N_works_completion_due'] = calculate_due_date(A_date, days_map.get(result['D_type'], 0))
    
    # O1: å‘ç»™æ‰¿åŒ…å•†çš„ä¼ çœŸæ—¥æœŸ (ä»…æ—¥æœŸéƒ¨åˆ†ï¼Œé€šå¸¸åŒA)
    result['O1_fax_to_contractor'] = A_date.strftime("%Y-%m-%d") if A_date else ""
    
    # O2: é‚®ä»¶å‘é€æ—¶é—´ (TMOä¸é€‚ç”¨)
    result['O2_email_send_time'] = ""
    
    # P: ä¼ çœŸé¡µæ•° (PDFé¡µæ•°)
    try:
        with pdfplumber.open(pdf_path) as pdf:
            result['P_fax_pages'] = str(len(pdf.pages))
    except:
        result['P_fax_pages'] = ""
    
    # Q: æ¡ˆä»¶è¯¦æƒ… (åç»­è¡ŒåŠ¨)
    result['Q_case_details'] = extract_follow_up_actions(content)
    
    return result


def _get_empty_result() -> Dict[str, Any]:
    """
    è¿”å›ç©ºçš„A-Qå­—æ®µç»“æœå­—å…¸
    
    Returns:
        Dict[str, Any]: åŒ…å«æ‰€æœ‰A-Qå­—æ®µçš„ç©ºå­—å…¸
    """
    return {
        'A_date_received': "",
        'B_source': "",
        'C_case_number': "",
        'D_type': "General",
        'E_caller_name': "",
        'F_contact_no': "",
        'G_slope_no': "",
        'H_location': "",
        'I_nature_of_request': "",
        'J_subject_matter': "Tree Trimming/ Pruning",
        'K_10day_rule_due_date': "",
        'L_icc_interim_due': "",
        'M_icc_final_due': "",
        'N_works_completion_due': "",
        'O1_fax_to_contractor': "",
        'O2_email_send_time': "",
        'P_fax_pages': "",
        'Q_case_details': ""
    }
