#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIrequestæ‘˜è¦ç”Ÿæˆå™¨module

æœ¬moduleä¸“é—¨ç”¨äºä»é‚®ä»¶æˆ–PDFï¼ˆä¼ çœŸï¼‰å†…å®¹ä¸­ç”Ÿæˆç®€æ´ã€å‡†ç¡®çš„requestæ‘˜è¦ã€‚
ä¸ä¼ ç»Ÿçš„é‚®ä»¶ç»“æ„extractä¸åŒï¼Œæœ¬moduleä¸“æ³¨äºè¯†åˆ«å’Œsummarizeå…·ä½“çš„requestå†…å®¹ã€‚

mainfunctionï¼š
1. æ™ºèƒ½è¯†åˆ«17ç§ä¸åŒclasså‹çš„requestæ¨¡å¼
2. ä»å¤æ‚å†…å®¹ä¸­extractæ ¸å¿ƒrequestinformation
3. ç”Ÿæˆç®€æ´çš„è‡ªç„¶è¯­è¨€æ‘˜è¦
4. æ”¯æŒå¤šè¯­è¨€å†…å®¹processï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰
5. æä¾›confidenceevaluateå’Œå†…å®¹èåˆ

æŠ€æœ¯ç‰¹ç‚¹ï¼š
- åŸºäºæ­£åˆ™tableè¾¾å¼çš„æ¨¡å¼match
- å¤šæºå†…å®¹èåˆç®—æ³•
- confidenceè¯„åˆ†æœºåˆ¶
- æ™ºèƒ½å†…å®¹cleanupå’Œformat

ä½œè€…: Project3 Team
ç‰ˆæœ¬: 2.0
"""

import re
from typing import Optional, Dict, List, Tuple
import os


class AIRequestSummarizer:
    """
    AIè¯·æ±‚æ‘˜è¦ç”Ÿæˆå™¨
    
    ä¸“é—¨ç”¨äºä»é‚®ä»¶æˆ–PDFå†…å®¹ä¸­extractå’Œsummarizeå…·ä½“çš„è¯·æ±‚informationï¼Œ
    ç”Ÿæˆç®€æ´ã€å‡†ç¡®çš„æ¡ˆä»¶è¯·æ±‚æ‘˜è¦ã€‚
    
    Attributes:
        request_patterns (List[Dict]): è¯·æ±‚è¯†åˆ«æ¨¡å¼åˆ—table
        content_extractors (Dict): å†…å®¹extractå™¨å­—å…¸
    """
    
    def __init__(self):
        """
        initializeæ‘˜è¦ç”Ÿæˆå™¨
        
        æ„å»ºè¯·æ±‚è¯†åˆ«æ¨¡å¼å’Œå†…å®¹extractå™¨ï¼Œç”¨äºåç»­çš„æ‘˜è¦ç”Ÿæˆã€‚
        """
        self.request_patterns = self._build_request_patterns()
        self.content_extractors = self._build_content_extractors()
    
    def _build_request_patterns(self) -> List[Dict]:
        """æ„å»ºè¯·æ±‚è¯†åˆ«æ¨¡å¼"""
        return [
            # ä¸­æ–‡queryæ¨¡å¼
            {
                'pattern': r'ä¸»æ—¨[ï¼š:]\s*([^\n]+)',
                'type': 'subject',
                'priority': 10,
                'description': 'é‚®ä»¶ä¸»æ—¨'
            },
            {
                'pattern': r'æŸ¥è©¢([^\nï¼Œã€‚]+)',
                'type': 'inquiry',
                'priority': 9,
                'description': 'queryè¯·æ±‚'
            },
            {
                'pattern': r'æŠ•è¨´([^\nï¼Œã€‚]+)',
                'type': 'complaint',
                'priority': 9,
                'description': 'æŠ•è¯‰å†…å®¹'
            },
            {
                'pattern': r'è¦æ±‚([^\nï¼Œã€‚]+)',
                'type': 'request',
                'priority': 8,
                'description': 'å…·ä½“è¦æ±‚'
            },
            {
                'pattern': r'ç”³è«‹([^\nï¼Œã€‚]+)',
                'type': 'application',
                'priority': 8,
                'description': 'ç”³è¯·äº‹é¡¹'
            },
            {
                'pattern': r'å ±å‘Š([^\nï¼Œã€‚]+)',
                'type': 'report',
                'priority': 7,
                'description': 'æŠ¥å‘Šäº‹é¡¹'
            },
            
            # è‹±æ–‡queryæ¨¡å¼
            {
                'pattern': r'Subject[ï¼š:]\s*([^\n]+)',
                'type': 'subject',
                'priority': 10,
                'description': 'Email Subject'
            },
            {
                'pattern': r'Request for ([^\n,.]+)',
                'type': 'request',
                'priority': 8,
                'description': 'Request for'
            },
            {
                'pattern': r'Enquiry about ([^\n,.]+)',
                'type': 'inquiry',
                'priority': 9,
                'description': 'Enquiry about'
            },
            {
                'pattern': r'Complaint regarding ([^\n,.]+)',
                'type': 'complaint',
                'priority': 9,
                'description': 'Complaint regarding'
            },
            {
                'pattern': r'Application for ([^\n,.]+)',
                'type': 'application',
                'priority': 8,
                'description': 'Application for'
            },
            
            # å…·ä½“å†…å®¹æ¨¡å¼
            {
                'pattern': r'æ–œå¡[ç·¨ç¼–è™Ÿå·]*[ï¼š:]?\s*([^\sï¼Œã€‚\n]+)',
                'type': 'slope_info',
                'priority': 6,
                'description': 'æ–œå¡information'
            },
            {
                'pattern': r'ç¶­ä¿®å·¥ç¨‹([^\nï¼Œã€‚]+)',
                'type': 'maintenance',
                'priority': 7,
                'description': 'ç»´ä¿®å·¥ç¨‹'
            },
            {
                'pattern': r'é€²åº¦([^\nï¼Œã€‚]*)',
                'type': 'progress',
                'priority': 6,
                'description': 'è¿›åº¦query'
            }
        ]
    
    def _build_content_extractors(self) -> List[Dict]:
        """æ„å»ºå†…å®¹extractå™¨"""
        return [
            # TXTfileå†…å®¹extract
            {
                'source': 'txt_outbound',
                'patterns': [
                    r'ä¸»æ—¨[ï¼š:]\s*([^\n]+)',
                    r'\[Detail\]\s*([^[]+?)(?=\[|$)',
                    r'Email - Outbound[^[]*?\[Detail\]\s*([^[]+?)(?=\[|$)'
                ],
                'priority': 10
            },
            {
                'source': 'txt_inbound',
                'patterns': [
                    r'Email - Inbound[^[]*?\[Detail\]\s*([^[]+?)(?=\[|$)',
                    r'WRITTEN CONTACT INBOUND DETAILS[^[]*?([^[]+?)(?=\[|$)'
                ],
                'priority': 8
            },
            
            # é‚®ä»¶å†…å®¹extract
            {
                'source': 'email_body',
                'patterns': [
                    r'We have received the following enquiry[ï¼š:]?\s*([^.]+)',
                    r'The citizen enquires about[ï¼š:]?\s*([^.]+)',
                    r'Enquiry details[ï¼š:]?\s*([^.]+)',
                    r'Request details[ï¼š:]?\s*([^.]+)'
                ],
                'priority': 9
            },
            
            # PDFå†…å®¹extract
            {
                'source': 'pdf_content',
                'patterns': [
                    r'Nature of complaint[ï¼š:]?\s*([^\n]+)',
                    r'Description[ï¼š:]?\s*([^\n]+)',
                    r'Details[ï¼š:]?\s*([^\n]+)',
                    r'Complaint[ï¼š:]?\s*([^\n]+)'
                ],
                'priority': 7
            }
        ]
    
    def generate_request_summary(self, content: str, email_content: str = None, 
                               content_type: str = 'txt') -> str:
        """
        ç”Ÿæˆè¯·æ±‚æ‘˜è¦
        
        Args:
            content: ä¸»è¦å†…å®¹ï¼ˆTXT/PDFå†…å®¹ï¼‰
            email_content: é‚®ä»¶å†…å®¹ï¼ˆå¯é€‰ï¼‰
            content_type: å†…å®¹classå‹ ('txt', 'pdf', 'email')
            
        Returns:
            str: ç”Ÿæˆçš„è¯·æ±‚æ‘˜è¦
        """
        print("ğŸ¤– å¼€å§‹AIè¯·æ±‚æ‘˜è¦ç”Ÿæˆ...")
        
        # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„requestinformation
        extracted_requests = []
        
        # 1. ä»mainå†…å®¹extract
        if content:
            main_requests = self._extract_requests_from_content(content, content_type)
            extracted_requests.extend(main_requests)
        
        # 2. ä»é‚®ä»¶å†…å®¹extract
        if email_content:
            email_requests = self._extract_requests_from_content(email_content, 'email')
            extracted_requests.extend(email_requests)
        
        # 3. æŒ‰ä¼˜å…ˆçº§sortå¹¶ç”Ÿæˆæ‘˜è¦
        if extracted_requests:
            # æŒ‰ä¼˜å…ˆçº§å’Œconfidencesort
            extracted_requests.sort(key=lambda x: (x['priority'], x['confidence']), reverse=True)
            
            # ç”Ÿæˆæ™ºèƒ½æ‘˜è¦
            summary = self._generate_intelligent_summary(extracted_requests)
            
            if summary:
                print(f"âœ… AIè¯·æ±‚æ‘˜è¦ç”Ÿæˆsuccess: {summary}")
                return summary
        
        # 4. å¦‚æœæ²¡æœ‰extractåˆ°å…·ä½“requestï¼Œä½¿ç”¨ä¼ ç»Ÿmethod
        fallback_summary = self._generate_fallback_summary(content, email_content)
        print(f"âš ï¸ ä½¿ç”¨å¤‡ç”¨æ‘˜è¦method: {fallback_summary}")
        return fallback_summary
    
    def _extract_requests_from_content(self, content: str, source_type: str) -> List[Dict]:
        """ä»å†…å®¹ä¸­extractè¯·æ±‚information"""
        requests = []
        
        if not content or not content.strip():
            return requests
        
        # ä½¿ç”¨requestæ¨¡å¼match
        for pattern_info in self.request_patterns:
            pattern = pattern_info['pattern']
            matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
            
            for match in matches:
                extracted_text = match.group(1).strip() if match.groups() else match.group(0).strip()
                
                if extracted_text and len(extracted_text) > 3:  # è¿‡æ»¤å¤ªçŸ­çš„åŒ¹é…
                    # calculateconfidence
                    confidence = self._calculate_confidence(extracted_text, pattern_info, source_type)
                    
                    requests.append({
                        'text': extracted_text,
                        'type': pattern_info['type'],
                        'priority': pattern_info['priority'],
                        'confidence': confidence,
                        'source': source_type,
                        'description': pattern_info['description']
                    })
        
        return requests
    
    def _calculate_confidence(self, text: str, pattern_info: Dict, source_type: str) -> float:
        """è®¡ç®—extractconfidence"""
        confidence = 0.5  # åŸºç¡€confidence
        
        # æ ¹æ®æ–‡æœ¬é•¿åº¦è°ƒæ•´
        if 10 <= len(text) <= 100:
            confidence += 0.2
        elif len(text) > 100:
            confidence += 0.1
        
        # æ ¹æ®æ¨¡å¼classå‹è°ƒæ•´
        if pattern_info['type'] in ['subject', 'inquiry', 'complaint']:
            confidence += 0.2
        
        # æ ¹æ®æ¥æºclasså‹è°ƒæ•´
        if source_type == 'txt' and pattern_info['type'] == 'subject':
            confidence += 0.3
        elif source_type == 'email' and 'enquiry' in text.lower():
            confidence += 0.2
        
        # æ ¹æ®å…³keyè¯è°ƒæ•´
        keywords = ['æ–œå¡', 'ç¶­ä¿®', 'å·¥ç¨‹', 'é€²åº¦', 'slope', 'maintenance', 'repair', 'progress']
        keyword_count = sum(1 for keyword in keywords if keyword.lower() in text.lower())
        confidence += keyword_count * 0.1
        
        return min(confidence, 1.0)  # æœ€å¤§confidenceä¸º1.0
    
    def _generate_intelligent_summary(self, requests: List[Dict]) -> Optional[str]:
        """ç”Ÿæˆæ™ºèƒ½æ‘˜è¦"""
        if not requests:
            return None
        
        # é€‰æ‹©æœ€é«˜ä¼˜å…ˆçº§å’Œconfidenceçš„request
        best_request = requests[0]
        
        # å¦‚æœæ˜¯ä¸»æ—¨classå‹ï¼Œç›´æ¥ä½¿ç”¨
        if best_request['type'] == 'subject' and best_request['confidence'] > 0.7:
            return self._clean_summary_text(best_request['text'])
        
        # ç»„åˆå¤šä¸ªç›¸å…³request
        summary_parts = []
        used_types = set()
        
        for request in requests[:3]:  # æœ€å¤šä½¿ç”¨å‰3ä¸ªè¯·æ±‚
            if request['confidence'] > 0.6 and request['type'] not in used_types:
                cleaned_text = self._clean_summary_text(request['text'])
                if cleaned_text:
                    summary_parts.append(cleaned_text)
                    used_types.add(request['type'])
        
        if summary_parts:
            # æ™ºèƒ½ç»„åˆæ‘˜è¦
            if len(summary_parts) == 1:
                return summary_parts[0]
            else:
                # checkæ˜¯å¦å¯ä»¥merge
                combined = self._combine_summary_parts(summary_parts)
                return combined
        
        return None
    
    def _clean_summary_text(self, text: str) -> str:
        """æ¸…ç†æ‘˜è¦æ–‡æœ¬"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
        text = re.sub(r'\s+', ' ', text).strip()
        
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'[^\w\s\-/ï¼š:ï¼Œã€‚()ï¼ˆï¼‰]', '', text)
        
        # é™åˆ¶é•¿åº¦
        if len(text) > 150:
            text = text[:150] + "..."
        
        return text
    
    def _combine_summary_parts(self, parts: List[str]) -> str:
        """ç»„åˆæ‘˜è¦éƒ¨åˆ†"""
        if not parts:
            return ""
        
        # checkæ˜¯å¦æœ‰duplicateå†…å®¹
        unique_parts = []
        for part in parts:
            is_duplicate = False
            for existing in unique_parts:
                if self._is_similar_content(part, existing):
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_parts.append(part)
        
        # æ™ºèƒ½ç»„åˆ
        if len(unique_parts) == 1:
            return unique_parts[0]
        elif len(unique_parts) <= 3:
            return " | ".join(unique_parts)
        else:
            return unique_parts[0] + " ç­‰å¤šé¡¹è¯·æ±‚"
    
    def _is_similar_content(self, text1: str, text2: str) -> bool:
        """checkå†…å®¹æ˜¯å¦ç›¸ä¼¼"""
        if not text1 or not text2:
            return False
        
        # ç®€å•çš„ç›¸ä¼¼åº¦check
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if len(words1) == 0 or len(words2) == 0:
            return False
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        similarity = intersection / union if union > 0 else 0
        return similarity > 0.6
    
    def _generate_fallback_summary(self, content: str, email_content: str = None) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ‘˜è¦"""
        # å°è¯•ä»å†…å®¹ä¸­extractä»»ä½•æœ‰æ„ä¹‰çš„information
        fallback_patterns = [
            r'ä¸»æ—¨[ï¼š:]\s*([^\n]+)',
            r'Subject[ï¼š:]\s*([^\n]+)',
            r'æŸ¥è©¢([^\nï¼Œã€‚]+)',
            r'Request for ([^\n,.]+)',
            r'Enquiry about ([^\n,.]+)',
            r'Description[ï¼š:]\s*([^\n]+)',
            r'Nature of complaint[ï¼š:]\s*([^\n]+)'
        ]
        
        sources = [content, email_content] if email_content else [content]
        
        for source in sources:
            if not source:
                continue
                
            for pattern in fallback_patterns:
                match = re.search(pattern, source, re.IGNORECASE)
                if match:
                    extracted = match.group(1).strip()
                    if extracted and len(extracted) > 5:
                        return self._clean_summary_text(extracted)
        
        # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
        if content and len(content.strip()) > 10:
            # extractå‰100ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
            summary = content.strip()[:100]
            if len(content.strip()) > 100:
                summary += "..."
            return self._clean_summary_text(summary)
        
        return "æ— æ³•extractå…·ä½“è¯·æ±‚å†…å®¹"


def generate_ai_request_summary(content: str, email_content: str = None, 
                              content_type: str = 'txt') -> str:
    """
    ç”ŸæˆAIè¯·æ±‚æ‘˜è¦çš„å…¥å£å‡½æ•°
    
    Args:
        content: ä¸»è¦å†…å®¹
        email_content: é‚®ä»¶å†…å®¹ï¼ˆå¯é€‰ï¼‰
        content_type: å†…å®¹classå‹
        
    Returns:
        str: ç”Ÿæˆçš„è¯·æ±‚æ‘˜è¦
    """
    summarizer = AIRequestSummarizer()
    return summarizer.generate_request_summary(content, email_content, content_type)


def test_ai_request_summarizer():
    """æµ‹è¯•AIè¯·æ±‚æ‘˜è¦ç”Ÿæˆå™¨"""
    print("=== AIè¯·æ±‚æ‘˜è¦ç”Ÿæˆå™¨æµ‹è¯• ===\n")
    
    # testç”¨ä¾‹
    test_cases = [
        {
            'name': 'æ–œå¡ç»´ä¿®query',
            'content': 'ä¸»æ—¨ï¼šæŸ¥è©¢æ–œå¡ç¶­ä¿®ç·¨è™Ÿ11SW-D/805ç¶­ä¿®å·¥ç¨‹é€²åº¦ (æª”æ¡ˆç·¨è™Ÿï¼š3-8641924612)',
            'email_content': None,
            'type': 'txt'
        },
        {
            'name': 'æ ‘æœ¨ä¿®å‰ªè¯·æ±‚',
            'content': 'Request for tree trimming at slope area 15NE-A/F91',
            'email_content': 'We have received the following enquiry: The citizen requests tree maintenance work.',
            'type': 'txt'
        },
        {
            'name': 'æ’æ°´é—®é¢˜æŠ•è¯‰',
            'content': 'æŠ•è¨´æ–œå¡æ’æ°´ç³»çµ±å µå¡å•é¡Œ',
            'email_content': None,
            'type': 'pdf'
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"ğŸ“‹ æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
        
        try:
            summary = generate_ai_request_summary(
                test_case['content'],
                test_case['email_content'],
                test_case['type']
            )
            
            print(f"   âœ… æ‘˜è¦result: {summary}")
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•failed: {e}")
        
        print()


if __name__ == "__main__":
    test_ai_request_summarizer()
